
\section{Dirac notation}
This section introduces the language of Dirac notation, its
denotational and axiomatic semantics, and describes D-Hammer approach
to equational reasoning. Three main ingredients of our language are:
\begin{itemize}
\item a rich typing discipline that distinguishes between scalars,
  kets, bras and operators, but supports sufficient overloading to
  remain close to standard Dirac notation;
\item higher-order, indexed (a.k.a.\, weakly dependent) types. It allows
  to formally encode defined symbols like transpose or trace, which
  are usually used to represent the term in an abstract manner;
\item operators with indefinite arities. Indefinite arities are
  instrumental for reasoning efficiently about associative and
  commutative (AC) symbols have indefinite arities, as they enable
  normalization by sorting.
\end{itemize}

\subsection{Language}
Since a Hilbert space $\mathcal{H}_V$ is dependent on the basis set
$V$, types for Dirac notation also depends on the type index.
Therefore, the language is organized into three layers: the index, the
type, and the term.  Terms represent concrete instances such as kets,
bras, and operators, which will be typed and checked. The index
represents classical data types and appears in type expressions to
differentiate between various Hilbert spaces and sets.

\begin{definition}[Index Syntax]
    The syntax for type indices is:
    \begin{align*}
        \sigma ::=\ & x \mid \sigma_1 \times \sigma_2.
    \end{align*}
\end{definition}
Here, \( x \) is a variable, and \( \sigma_1 \times \sigma_2 \) represents the product type for tensor product spaces or Cartesian product sets.

\begin{definition}[Type Syntax]
    The syntax for Dirac notation types is:
    \begin{align*}
        T ::=\ & \Basis(\sigma) \mid \SType \mid \KType(\sigma) \mid \BType(\sigma) \mid \OType(\sigma_1, \sigma_2) \mid T_1 \to T_2 \mid \forall x.T \mid \SET(\sigma).
    \end{align*}
\end{definition}
\( \Basis(\sigma) \) denotes the type for basis elements in the index
\( \sigma \).  \( \SType \) represents scalars, while \(
\KType(\sigma) \) and \( \BType(\sigma) \) refer to ket and bra types
in the Hilbert space \( \sigma \), respectively.  \( \OType(\sigma_1,
\sigma_2) \) represents linear operators with \( \sigma_2 \) as the
domain and \( \sigma_1 \) as the codomain.  \( \SET(\sigma) \) refers
to the type of subsets of \( \sigma \), used to denote the values of
bound variables in summations.  The remaining two constructs define
function types: \( T_1 \to T_2 \) represent the set of functions that
take a \( T_1 \)-type argument and return a \( T_2 \)-type term, while
\( \forall x. T \) represents the dependently typed functions that
take an index argument \( x :\Index \) and produce a \( T \)-type
term, where $T$ may depend on \( x \).  Index functions are essential
for defining polymorphic transformations over Hilbert spaces.


\begin{definition}[Term Syntax]
    The syntax for Dirac notation terms is:
    \begin{align*}
        e ::=\ & x \mid \lambda x : T.e \mid \lambda x : \Index.e \mid e_1\ e_2 \mid (e_1, e_2) \\
        & |\ 0 \mid 1 \mid e_1 \times \cdots \times e_n \mid e^* \mid \delta_{e_1, e_2} \\
        & |\ \ZEROK(\sigma) \mid \ZEROB(\sigma) \mid \ZEROO(\sigma_1, \sigma_2) \mid \ONEO(\sigma) \\
        & |\ \ket{e} \mid \bra{t} \mid e^\dagger \mid e_1.e_2 \mid e_1 + \cdots + e_n \mid e_1 \otimes e_2 \mid e_1 \cdot e_2 \\
        & |\ \mathbf{U}(\sigma) \mid e_1 \star e_2 \mid \sum_{e_1} e_2.
    \end{align*}
\end{definition}
The terms above are explained in five lines.
\begin{enumerate}
    \item \textbf{function and basis}: \( \lambda x : T.e \) represents the abstraction for normal functions, and \( \lambda x : \Index.e \) represents the abstraction for index functions.
    \( e_1\ e_2 \) denotes function application.
    \( (e_1, e_2) \) is the basis pair for product types.
    \item \textbf{scalar}: \( 0 \), \( 1 \), \( e_1 \times \cdots \times e_n \) and \( e^* \) are symbols for scalars.
    \( \delta_{e_1, e_2} \) compares whether two basis are the same and evaluates to $1$ or $0$ accordingly.
    \item \textbf{Dirac constant}: zero ket, zero bra, zero operator and identity operator.
    \item \textbf{Dirac function}: \( \ket{e} \) is a ket, \( \bra{t} \) is a bra, and \( e^\dagger \) denotes the conjugate transpose of \( e \). \( e_1.e_2 \) represents scaling the term \( e_2 \) by scalar \( e_1 \). \(e_1 + \cdots + e_n\) is the addition. \( e_1 \otimes e_2 \) represents tensor product, and \( e_1 \cdot e_2 \) represents the multiplication.
    \item \textbf{summation}: \( \mathbf{U}(\sigma) \) denotes the universal set with index \( \sigma \). \( e_1 \star e_2 \) represents the Cartesian product of \( e_1 \) and \( e_2 \). \( \sum_{e_1} e_2 \) is the big operator sum, modeled by folding the function \( e_2 \) over the value set \( e_1 \). Typically, the sum's body is given by an abstraction. For convenience, we also use the notation \( \sum_{x \in s} X \) to represent \( \sum_{s} \lambda x : T . X \).
\end{enumerate}

The scalar multiplication $\times$ and addition $+$ are AC symbols,
and they have indefinite arity.  We use letters like $a, b, c$ to
represent scalar variables, $K$ and $B$ to represent ket and bra
variables, and $O$ for operators.  Therefore, $O \cdot K$ is
interpreted as the operator-ket multiplication, and scalars can also
be constructed from inner products $B \cdot K$.


\subsection{Typing System}
The typing system is responsible for classifying terms within a proof system, according to the types of variables and definitions. 
We use a context \( \Gamma \) to preserve the assumptions \( x : T \) and definitions \( x := t : T \).
\begin{definition}[Context]
    The syntax for context \( \Gamma \) is:
    \begin{align*}
        \Gamma ::= &\ [] \mid \Gamma; x : \Index \mid \Gamma; x : T \mid \Gamma; x := t : T.
    \end{align*}
\end{definition}
Definitions refer to symbols that can be expanded or unfolded, and typically represent abstract concepts. such as transpose or trace in Dirac notation. Assumptions, on the other hand, define the types of variables.
We say an expression \( t \) has type \( X \) in context \( \Gamma \) if the typing judgment \( \Gamma \vdash t : X \) can be proven through the rules in Appendix A. These are two instances:
\begin{gather*}
    \frac{\Gamma \vdash t : \Basis(\sigma)}{\Gamma \vdash \ket{t} : \KType(\sigma)},
    \qquad
    \frac{\Gamma \vdash B : \BType(\sigma) \qquad \Gamma \vdash K : \KType(\sigma)}{\Gamma \vdash B \cdot K : \SType}.
\end{gather*}
The ket \( \ket{t} \) will have the type \( \KType(\sigma) \) if \( t \) is a basis term of index \( \sigma \). Similarly, the inner product between a bra and a ket of the same index \( \sigma \) is typed as a scalar. It corresponds to the constraint of inner product that vectors should be from the same Hilbert space.
Especially, the big operator sum is modeled by folding a function over a set, with the typing rule as follows:
\[
    \frac{\Gamma \vdash s : \SET(\sigma) \qquad \Gamma \vdash f : \Basis(\sigma) \to \KType(\tau)}{\Gamma \vdash \sum_{s} f : \KType(\tau)}.
\]

% \begin{lemma}
%     The typing of expressions is both decidable and unique.
% \end{lemma}

% \begin{proof}
%     The type of an expression can be determined recursively. For any given function symbol and argument types, there is at most one typing rule, ensuring the uniqueness of typing.
% \end{proof}






\subsection{Semantics}

The semantics of a language define the meaning of its expressions. In this context, the objective of our algorithm is to determine whether two expressions are semantically equivalent. We define the semantics in a denotational manner, mapping syntax to set-theoretic objects.

\subsubsection{Denotational Semantics}
Denotational semantics maps types to sets, and expressions and
indices to values in the interpretation of types and indices,
respectively. As in other dependently typed systems, all
interpretations are parametrized by a valuation mapping \( v \), which
assigns values to variables and indices. We let \( \sem{e}_v \) denote
the interpretation of an expression $e$ w.r.t.\, a valuation \( v \),
and use similar notations for types and indices. As usual, we say that
a valuation \( v \) is valid w.r.t.\, a context $\Gamma$ if for every
variable declaration $x:T$, we have \( \sem{x}_v \in\sem{T}_v \) and
for every definition $x:= t: T$, we have  \( \sem{x}_v=\sem{t}_v \).


In more detail, variables typed with \( \Index \) are interpreted as
finite sets, and the product of two indices \( \sem{\sigma_1 \times
  \sigma_2} \) is defined as the Cartesian product of the sets \(
\sem{\sigma_1} \) and \( \sem{\sigma_2} \). More generally, each type
is interpreted as a set. For example, the scalar type \( \sem{\SType}
\) is interpreted as the set of complex numbers \( \mathbb{C} \), and
the ket and bra types \( \sem{\KType(\sigma)} \) and \(
\sem{\BType(\sigma)} \) are interpreted as the Hilbert space \(
\mathcal{H}_{\sem{\sigma}} \) and its dual \(
\mathcal{H}_{\sem{\sigma}}^* \), respectively. Terms are explained as
the set elements. For example, the semantics of ket tensor product
$\sem{K_1 \otimes K_2} \equiv \sem{K_1} \otimes \sem{K_2}$, is
obtained by first calculating the semantics $\sem{K_1}$ and
$\sem{K_2}$ as vectors, and then take the vector tensor product as
result.  The complete interpretation of terms and types is provided
in Appendix B.

% One special case is the delta function \( \delta_{s,t} \), which is interpreted as:
% \[
%     \sem{\delta_{s,t}} =
%     \begin{cases}
%         1, & \text{if } \sem{s} = \sem{t}, \\
%         0, & \text{if } \sem{s} \neq \sem{t}.
%     \end{cases}
% \]d

The type system is sound w.r.t.\, the denotational semantics of
expressions. Specifically, for a well-formed context \( \Gamma \), term \( t \), and type \( T \), if \( \Gamma \vdash t : T \), then for any valuation \( v \) that is valid for $\Gamma$, the interpretation of \( t \)  w.r.t.\, $v$ is an element of the interpretation of \( T \) w.r.t.\, $v$.

\begin{lemma}[Soundness of type system]
  \label{lemma:sound type system}
  If \( \Gamma \vdash t : T \), then for all valuations \( v \) valid w.r.t.\,
  $\Gamma$, we have \( \sem{t}_v \in \sem{T}_v \).
\end{lemma}
% \begin{proof}
% By induction on the derivation.
% \end{proof}
This interpretation formalizes the standard understanding of Dirac
notation and provides the foundation for the algorithm. However,
computers cannot directly reason about equivalence through
mathematical interpretations. We proceed by defining a proof system
that abstracts these concepts.



\subsubsection{Axiomatic semantics} 

The proof system for equivalence is based on equational logic, together with axioms that describe the properties of Dirac notation. A full list of these axioms can be found in Appendix C. The axioms cover fundamental aspects of linear spaces, as well as other structures like the tensor and inner products. For example, we have the absorption law for zero symbols:
\(X \cdot \mathbf{0} = \mathbf{0},\)
and the bilinearity of the dot product:
\begin{align*}
(a.X) \cdot Y = a \cdot (X \cdot Y), \quad X \cdot (Y_1 + Y_2) = X \cdot Y_1 + X \cdot Y_2, \\
X \cdot (a.Y) = a \cdot (X \cdot Y), \quad (X_1 + X_2) \cdot Y = X_1 \cdot Y + X_2 \cdot Y.
\end{align*}
The entire axioms are separated into two sets $R$ and $E$.
$R$ contains the axioms normalized by term rewriting. Other axioms requiring special algorithms, which are collected in the set $E$.
\begin{definition}[axiom set E]
\label{def: axiom E}
\begin{align*}
    \textup{(AC-equivalence)} &\ \text{e.g.,} \quad X + Y = Y + X, \quad (X + Y) + Z = X + (Y + Z), \\
    \textup{($\alpha$-equivalence)} &\ \lambda x . A = \lambda y . A\{x/y\},
    \quad
    \textup{(SUM-SWAP)} \ \sum_{i \in s_1} \sum_{j \in s_2} A = \sum_{j \in s_2} \sum_{i \in s_1} A, \\
    \textup{(scalar theories)} &\ \text{e.g.,} \quad a + 0 = a, \quad a \times (b + c) = a \times b + a \times c.
\end{align*}
\end{definition}

% These equational axioms provide an operable theory for the proof automation algorithm. Denotational semantics can be seen as one model for this theory, meaning that equivalences derived from the axioms always imply equivalence in the interpretations.


We say an equation $e_1 = e_2$ is provable, denoted as $\Gamma \vdash e_1 = e_2 : T$, if $\Gamma \vdash e_1 : T$ and $\Gamma \vdash e_2 : T$ are provable, and $e_1 = e_2$ can be deduced in $\Gamma$ using the axioms and equational logic.
An equation \( e_1 = e_2 \) is valid in context $\Gamma$, written as \(
\Gamma \vDash e_1 = e_2 \), if \( \sem{e_1}_v = \sem{e_2}_v \) for
all valuations \( v \) that are valid w.r.t.\, \( \Gamma \).

\begin{theorem}[Soundness of equational theory]\label{lem: axiom sound}
If \( \Gamma \vdash e_1 = e_2 :T \) then \( \Gamma \vDash e_1 = e_2\).
\end{theorem}
The proof of soundess is standard: we prove that all axioms are sound,
and that all proof rules are sound.

% \begin{proof}
% By induction on the structure of the derivation
% \end{proof}
Next, we formalize the motivating example~\Cref{ex: motivating} in
Dirac notation.
\begin{example}[Motivating Example Formalization]
    \label{ex: formalizing motivating}
    Definitions and assumptions in the context \( \Gamma \) are formalized as follows:
    \begin{align*}
        & \text{TPO} && := \lambda T_1 : \Index. \lambda T_2 : \Index. \lambda O : \OType(T_1, T_2). \sum_{i \in \mathbf{U}(T_1)} \sum_{j \in \mathbf{U}(T_2)} \bra{i} O \ket{j} . \ket{j}\bra{i} \\
        & &&\quad : \forall T_1. \forall T_2. \OType(T_1, T_2) \to \OType(T_2, T_1); \\
        &\text{phi} &&:= \lambda T : \Index. \sum_{i \in \mathbf{U}(T)} \sum_{j \in \mathbf{U}(T)} \ket{(i, j)} : \forall T.\KType(T \times T); \\
        & T && : \Index;  \qquad \qquad \qquad \qquad \qquad M \qquad : \OType(T, T).
    \end{align*}
    Notice how the functions and higher-order typing helps to formalize the abstract concepts here.
    The symbol \( \text{TPO} \) represents the transpose of an operator, polymorphic on the Hilbert spaces \( T_1 \) and \( T_2 \). 
    The symbol \( \text{phi} \) takes the index \( T \) and defines the maximally entangled states, summing over all basis elements in \( T \), as indicated by the universal set \( \mathbf{U}(T) \).
    With the assumption of the index \( T \) and operator \( M \), we can express the equivalence in the plain Dirac notation as:
    \[
    (\textrm{M} \otimes \mathbf{1}_\mathcal{O}(\textrm{T})) \cdot (\textrm{phi T}) = (\mathbf{1}_\mathcal{O}(\textrm{T}) \otimes (\textrm{TPO T T M})) \cdot (\textrm{phi T}).
    \]
\end{example}



\subsection{Normalization}

The equivalence of Dirac notations is established through normalization, which transforms equivalent expressions into the same syntax under a set of axioms. We employ an efficient algorithm to perform the normalization fully on $R \cup E$.

\begin{enumerate}
    \item \textbf{Rule based term rewriting}: Expand definitions and simplify expressions.
    \item \textbf{Variable expansion}: Convert to abstract element-wise representation.
    \item \textbf{Rule based term rewriting}: Normalize terms on \( R \) modulo \( E \).
    \item \textbf{Sorting without bound variables}: Normalize AC-equivalence.
    \item \textbf{Swapping successive summations}: Normalize SUM-SWAP equivalence.
    \item \textbf{Use de Bruijn index}: Normalize \( \alpha \)-equivalence.
\end{enumerate}

Step 1 through 3 involve term rewriting for $R$. 
Term rewriting is the process of repeatedly reducing a term using a set of rules in the form of $l\ \reduce\ r$. The reduction works by matching the subterms with the left-hand side of a rule and replacing it with the right-hand side. 
For example, the term $(x\times y) . \ket{t} + \ket{t}$ is matched by the rule $a.K + K\ \reduce\ (a + 1).K$, and is rewritten into $(x\times y + 1) . \ket{t}$.
Step 1 and 3 use the same set of rewriting rules in Appendix D.
Step 2 expands variables to their abstract element-wise representation, e.g., $K \ \reduce\ \sum_{i} (\bra{i} \cdot K). \ket{i}$, which is useful when reasoning about sums. 


Steps 4 through 6 are specialized algorithms designed to further normalize the axiom set $E$.
The main challenge here is the coexistence of AC-equivalence and SUM-SWAP, which means that naive sorting cannot alwasy convert equivalent terms into the same form.
For step 4 and 5, the key observation is that in a successive sum expression \( \sum_{i \in s_1} \cdots \sum_{j \in s_n} A \), the names and order of the bound variables \( i, \dots, j \) can be freely permuted. Therefore we first ignore bound variables and normalize AC-equivalence by sorting. Afterward, the order of summation can be established accordingly. The final step uses de Bruijn indices~\cite{deBruijn1972lambda} to resolve $\alpha$-equivalence. For further details, refer to Appendix E.


\Cref{fig: normalization demo} shows the normalization outline for $(M \otimes \mathbf{1}_\mathcal{O}(T)) \cdot (\text{phi}\ T)$.
\begin{figure}[h]
    \scriptsize
    \begin{align*}
        & (\eqnmarkbox[blue]{mvar}{M} \otimes \eqnmarkbox[red]{identity}{\mathbf{1}_\mathcal{O}(T)})(\eqnmarkbox[red]{phi-definition}{\textrm{phi}\ T})
        \Rightarrow
        (\sum_{k,l\in T} \bra{k} M \ket{l}.\ket{k}\bra{l}
        \eqnmarkbox[red]{sumpush1}{\otimes \sum_{i \in T}} \ket{i}\bra{i})(\eqnmarkbox[red]{sumpush2}{\sum_{j\in T}}\ket{j, j}) 
        \\
        & \Rightarrow
        \sum_{i,j,k,l\in T} \bra{k} M \ket{l} . \ket{k, i}\eqnmarkbox[red]{braket-dot}{\bra{l, i} \cdot \ket{j,j}}
        \\
        & \Rightarrow
        \eqnmarkbox[red]{delta-elim-sum}{\sum_{i,j,k,l\in T}} (\eqnmarkbox[red]{delta-elim-delta}{\delta_{l,j} \times \delta_{i,j}} \times \bra{k} M \ket{l}) . \ket{k, i}
        \Rightarrow
        \eqnmarkbox[brown]{swapsum}{\sum_{j, k \in T}} \bra{k} M \ket{j} . \ket{k, j}
        \\[1em]
        & \Rightarrow
        \sum_{k, j \in T} \bra{k} M \ket{j} . \ket{k, j}
        \ \eqnmarkbox[brown]{deBruijn}{\xRightarrow{\text{de Bruijn}}}\ 
        \sum_T\sum_T\bra{\$1} M \ket{\$0} . \ket{\$1, \$0}
    \end{align*}
    \annotate[yshift=1em]{right}{mvar}{\scriptsize{variable expansion}}
    \annotate[yshift=0.5em, xshift=1cm]{right}{identity}{\scriptsize{identity operator}}
    \annotate[yshift=0em]{below,left}{phi-definition}{\scriptsize{definition}}
    \annotatetwo[yshift=0em]{below}{sumpush1}{sumpush2}{\scriptsize{sum lifting}}
    \annotate[yshift=0em]{below}{braket-dot}{\scriptsize{inner product}}
    \annotatetwo[yshift=0em,xshift=2cm]{below}{delta-elim-sum}{delta-elim-delta}{\scriptsize{$\delta$-elimination}}
    \annotate[yshift=0em]{below}{swapsum}{\scriptsize{sum swapping}}
    \caption{A normalization outline for the left-hand side of~\Cref{eq: motivating plain}. Matched subterms are marked with colors. Blue marking represents variable expansion, red marking represents rule applications, and brown marking represents normalization step 4-6.}
    \label{fig: normalization demo}
\end{figure}

In contrast, previous work performs normalization only partially on $R$, and proves equivalence by checking all possible permutations according to $E$.
Our algorithm fully normalize the term, as illustrated below, and is more efficient as a result.
\[
\text{(partial)}\qquad e_1 \mathop{\twoheadrightarrow}^R e_1' \mathop{=}^E e_2' \mathop{\twoheadleftarrow}^R e_2
\qquad
\text{(full)}\qquad e_1 \mathop{\twoheadrightarrow}^{R \cup E} e \equiv e \mathop{\twoheadleftarrow}^{R \cup E} e_2
\]
% While the permutation checking algorithm has factorial complexity on the number of AC symbol arguments, our algorithm uses normalization by sorting, and the complexity is polynomial on the term size. 
% This improvement in efficiency is also confirmed by experiments.

% \begin{gather*}
%     \eqnmarkbox[blue]{node1}{GEBV} = \sum_{i}^{n} \eqnmarkbox[red]{node2}{X_{i}} b_{i} \\
%     \eqnmarkbox[green]{node3}{ssssss}
% \end{gather*}
    
%     \annotate[yshift=1em]{left}{node1}{Genomic Estimated Breeding Value}
%     \annotate[yshift=-1em]{below}{node2}{Genotype at locus i}
%     \annotatetwo[yshift=2em]{above}{node2}{node3}{var 1}




% Lastly, we can prove that the equivalence established by this normalization procedure is sound with respect to the semantics.

% \begin{theorem}[Soundness]
%     For any well-formed context \( E \) and well-typed expressions \( e_1 \) and \( e_2 \), if  $e_1$ and $e_2$ have the same normal form, then \( \sem{e_1} = \sem{e_2} \).
% \end{theorem}
% \begin{proof}
%     Because of~\Cref{lem: axiom sound}, we only need to prove soundness with respect to axioms. 
%     This is because the term rewriting procedure follows from the fact that each rewriting rule preserves equivalence. Furthermore, the operations in the sort and swap transformations respect the AC-equivalence and SUM-SWAP axioms. Finally, the de Bruijn normalization ensures soundness for \( \alpha \)-equivalence.
% \end{proof}
