
\section{Language, Typing and Semantics}
The first step is to formalize the language for Dirac notation. In DiracDec, the language has a concrete design, where the same syntax for different types corresponds to distinct symbols. Our goal is to transition from this concrete design to a more abstract one, which aligns more closely with the conventional Dirac notation we use and simplifies the term rewriting system.

To achieve this, we organize our language into three layers: the index, the type, and the term. Terms represent concrete instances such as kets, bras, and operators, which will be typed and checked. The index represents classical data types and appears in type expressions to differentiate between various Hilbert spaces and sets.

\begin{definition}[Index Syntax]
    The syntax for type indices is:
    \begin{align*}
        \sigma ::=\ & x \mid \sigma_1 \times \sigma_2.
    \end{align*}
\end{definition}
Here, \( x \) is a variable, and \( \sigma_1 \times \sigma_2 \) represents the product type for tensor product spaces or Cartesian product sets.

\begin{definition}[Type Syntax]
    The syntax for Dirac notation types is:
    \begin{align*}
        T ::=\ & \Basis(\sigma) \mid \SType \mid \KType(\sigma) \mid \BType(\sigma) \mid \OType(\sigma_1, \sigma_2) \mid T_1 \to T_2 \mid \forall x.T \mid \SET(\sigma).
    \end{align*}
\end{definition}
\( \Basis(\sigma) \) denotes the type for basis elements in the index \( \sigma \).
\( \SType \) represents scalars, while \( \KType(\sigma) \) and \( \BType(\sigma) \) refer to ket and bra types in the Hilbert space \( \sigma \), respectively.
\( \OType(\sigma_1, \sigma_2) \) represents linear operators with \( \sigma_2 \) as the domain and \( \sigma_1 \) as the codomain.
\( \SET(\sigma) \) refers to the type of subsets of \( \sigma \), used to denote the values of bound variables in summations.
The remaining two constructs define function types: \( T_1 \to T_2 \) represents normal functions that take a \( T_1 \)-type argument and return a \( T_2 \)-type term, while \( \forall x. T \) represents index functions that take an index argument \( x \) and produce a \( T \)-type term, which may depend on \( x \).
Index functions are essential for defining polymorphic transformations across Hilbert spaces.


\begin{definition}[Term Syntax]
    The syntax for Dirac notation terms is:
    \begin{align*}
        e ::=\ & x \mid \lambda x : T.e \mid \mu x.e \mid e_1\ e_2 \mid (e_1, e_2) \\
        & |\ 0 \mid 1 \mid \ADDS(e_1, \cdots, e_n) \mid e_1 \times \cdots \times e_n \mid e^* \mid \delta_{e_1, e_2} \mid \DOT(e_1, e_2) \\
        & |\ \ZEROK(\sigma) \mid \ZEROB(\sigma) \mid \ZEROO(\sigma_1, \sigma_2) \mid \ONEO(\sigma) \\
        & |\ \ket{e} \mid \bra{t} \mid e^\dagger \mid e_1.e_2 \mid \ADD(e_1, \cdots, e_n) \mid e_1 \otimes e_2 \\
        & |\ \MULK(e_1, e_2) \mid \MULB(e_1, e_2) \mid \OUTER(e_1, e_2) \mid \MULO(e_1, e_2) \\
        & |\ \mathbf{U}(\sigma) \mid e_1 \star e_2 \mid \sum_{e_1} e_2.
    \end{align*}
\end{definition}
The terms above are explained in order:
\( \lambda x : T.e \) represents the abstraction for normal functions, and \( \mu x.e \) represents the abstraction for index functions.
\( e_1\ e_2 \) denotes function application.
\( (e_1, e_2) \) is the basis pair for product types.
The constants \( 0 \), \( 1 \), \( \ADDS \), \( e_1 \times \cdots \times e_n \), and \( e^* \) are symbols for scalars.
The next line includes constant symbols for kets, bras, and operators.
\( \ket{e} \) is a ket, \( \bra{t} \) is a bra, and \( e^\dagger \) denotes the conjugate transpose of \( e \).
\( e_1.e_2 \) represents scaling the term \( e_2 \) by scalar \( e_1 \).
\( \mathbf{U}(\sigma) \) denotes the universal set with index \( \sigma \).
\( e_1 \star e_2 \) represents the Cartesian product of \( e_1 \) and \( e_2 \).
\( \sum_{e_1} e_2 \) is the big operator sum, modeled by folding the function \( e_2 \) over the value set \( e_1 \). Typically, the sum's body is given by an abstraction. For convenience, we also use the notation \( \sum_{x \in s} X \) to represent \( \sum_{s} \lambda x : T . X \).
Additionally, \( \ADDS \) and \( \ADD \) are distinct AC symbols: \( \ADDS \) is used for scalar addition and \( \ADD \) for linear algebra addition.
There are five kinds of linear algebraic multiplications among kets, bras, and operators. These are encoded using five different symbols: \( \DOT \), \( \MULK \), \( \MULB \), \( \OUTER \), and \( \MULO \).

Compared to DiracDec, the symbols for addition, adjoint, scaling, and tensor products have been consolidated.
The multiplications are still kept separate due to their differing properties.
These operations are denoted as \( B \cdot K \), \( K_1 \cdot K_2 \), \( B_1 \cdot B_2 \), \( K \cdot B \), and \( O_1 \cdot O_2 \), respectively.




\subsection{Typing System}


The typing system is responsible for classifying terms within a proof system, using a context that specifies the types of variables and definitions. The context is divided into two components: the environment \( E \), which includes definitions and assumptions, and the context \( \Gamma \), which tracks bound variables. Both \( E \) and \( \Gamma \) consist of sequences of assumptions \( x : T \) or definitions \( x := t : T \).
\begin{definition}[Environment and Context]
    The syntax for \( E \) and \( \Gamma \) is:
    \begin{align*}
        E ::= &\ [] \mid E; x : \Index \mid E; x : T \mid E; x := t : T. \\
        \Gamma ::= &\ [] \mid \Gamma; x : \Index \mid \Gamma; x : T.
    \end{align*}
\end{definition}
Definitions refer to symbols that can be expanded or unfolded, and typically represent abstract concepts, such as transpose or trace in Dirac notation. Assumptions, on the other hand, define the types of variables, and variable assumptions are implicitly universally quantified in the case of equational proofs.

Type checking in our language involves maintaining a well-formed environment and context \( E[\Gamma] \). We say an expression \( t \) has type \( X \) in context \( E[\Gamma] \) if the typing judgment \( E[\Gamma] \vdash t : X \) can be proven through the rules in~\Cref{sec: full typing rules}. The well-formedness of the context \( \WF(E)[\Gamma] \) is built incrementally:
\[
    \frac{}{\WF([])[]}
    \qquad
    \frac{\WF(E)[] \qquad x \notin E}{\WF(E; x : \Index)[]}
    \qquad
    \frac{E[]\vdash t:T \qquad x \notin E}{\WF(E; x := t:T)[]}.
\]
Starting with an empty context, new index symbols can be introduced, and symbols with checked types can be defined. Typing judgments are then made inductively using the information from \( E[\Gamma] \). For instance, the rule \( x : \Index \in E[\Gamma] \) holds if \( E \) or \( \Gamma \) contains an assumption for \( x \).
And \(\KType(\sigma)\) is a valid type for kets, if the argument $\sigma$ is typed as an index.
\begin{gather*}
    \frac{\WF(E)[\Gamma] \qquad x : \Index \in E[\Gamma]}{E[\Gamma] \vdash x : \Index}
    \qquad
    \frac{E[\Gamma] \vdash \sigma : \Index}{E[\Gamma] \vdash \KType(\sigma) : \Type}
\end{gather*}

Terms are then typed accordingly.
For example, the ket \( \ket{t} \) will have the type \( \KType(\sigma) \) if \( t \) is a basis term of index \( \sigma \). Similarly, the inner product between a bra and a ket of the same index \( \sigma \) is typed as a scalar. It corresponds to the constraint of inner product that vectors should be from the same Hilbert space.
\begin{gather*}
    \frac{E[\Gamma]\vdash t : \Basis(\sigma)}{E[\Gamma] \vdash \ket{t} : \KType(\sigma)}
    \qquad
    \frac{E[\Gamma]\vdash B : \BType(\sigma) \qquad E[\Gamma]\vdash K : \KType(\sigma)}{E[\Gamma] \vdash B \cdot K : \SType}
\end{gather*}

The typing for functions and applications follows the standard practice. For example, the index function \( \mu x. t \) is typed with \( x \) as a bound variable of type \( \Index \), and the application \( (t\ u) \) has the type \( U\{x/u\} \), obtained by replacing \( x \) with the index instance \( u \).
\begin{gather*}
    \frac{E[\Gamma; x : T] \vdash t : U}{E[\Gamma] \vdash (\lambda x : T . t) : T \to U}
    \qquad
    \frac{E[\Gamma] \vdash t:U \to T \qquad E[\Gamma] \vdash u:U}{E[\Gamma] \vdash (t\ u):T} 
    \\[1em]
    \frac{E[\Gamma; x : \Index] \vdash t : U}{E[\Gamma] \vdash (\mu x.t) : \forall x.U}
    \qquad
    \frac{E[\Gamma] \vdash t:\forall x.U \qquad E[\Gamma] \vdash u : \Index}{E[\Gamma] \vdash (t\ u):U\{x/u\}}
\end{gather*}

Finally, the big operator sum is modeled by folding a function over a set, with the typing rule as follows:
\[
    \frac{E[\Gamma] \vdash s : \SET(\sigma) \qquad E[\Gamma] \vdash f : \Basis(\sigma) \to \KType(\tau)}{E[\Gamma] \vdash \sum_{s} f : \KType(\tau)}.
\]

\begin{lemma}
    The typing of expressions is both decidable and unique.
\end{lemma}

\begin{proof}
    The type of an expression can be determined recursively. For any given function symbol and argument types, there is at most one typing rule, ensuring the uniqueness of typing.
\end{proof}






\subsection{Semantics}

The semantics of a language define the meaning of its expressions. In this context, the objective of our algorithm is to determine whether two expressions are semantically equivalent. We define the semantics in a denotational manner, mapping syntax to set-theoretic objects.

\subsubsection{Denotational Semantics}
The denotational semantics interpret every expression as an object in linear algebra, according to a valuation mapping \( v \), which assigns values to the variables in the expression. The semantics of an expression \( e \) with a given valuation \( v \) is denoted as \( \sem{e}_v \). Two expressions \( e_1 \) and \( e_2 \) are considered equivalent if their semantics are equal for all valuations, i.e., \( \sem{e_1}_v = \sem{e_2}_v \) for all \( v \).

The complete interpretation of terms and types is provided in~\Cref{sec: full denotational sem}. Variables typed with \( \Index \) are interpreted as finite sets, and the product of two indices \( \sem{\sigma_1 \times \sigma_2} \) is defined as the Cartesian product of the sets \( \sem{\sigma_1} \) and \( \sem{\sigma_2} \). More generally, each type is interpreted as a set. For example, the scalar type \( \sem{\SType} \) is interpreted as the set of complex numbers \( \mathbb{C} \), and the ket and bra types \( \sem{\KType(\sigma)} \) and \( \sem{\BType(\sigma)} \) are interpreted as the Hilbert space \( \mathcal{H}_{\sem{\sigma}} \) and its dual \( \mathcal{H}_{\sem{\sigma}}^* \), respectively. Terms are explained as the set elements. For example, the semantics of ket tensor product $\sem{K_1 \otimes K_2} \equiv \sem{K_1} \otimes \sem{K_2}$, is obtained by first calculating the semantics $\sem{K_1}$ and $\sem{K_2}$ as vectors, and then take the vector tensor product as result.

% One special case is the delta function \( \delta_{s,t} \), which is interpreted as:
% \[
%     \sem{\delta_{s,t}} =
%     \begin{cases}
%         1, & \text{if } \sem{s} = \sem{t}, \\
%         0, & \text{if } \sem{s} \neq \sem{t}.
%     \end{cases}
% \]d

The idea behind the interpretation of types and terms is to formalize the typing relation using set-theoretic inclusion. Specifically, for a well-formed context \( E[\Gamma] \), term \( t \), and type \( T \), if \( E[\Gamma] \vdash t : T \), then for any valuation \( v \), the semantics of \( t \) must lie within the semantics of \( T \).

\begin{lemma}
    For any well-formed context \( E[\Gamma] \), term \( t \), and type \( T \), if \( E[\Gamma] \vdash t : T \), then for all valuations \( v \), \( \sem{t}_v \in \sem{T}_v \).
\end{lemma}

\begin{proof}
    The proof follows directly by checking each case.
\end{proof}

This interpretation formalizes the standard understanding of Dirac notation and provides the foundation for the algorithm. However, computers cannot directly reason about equivalence through mathematical interpretations. Therefore, we proceed by defining a proof system that abstracts these concepts.



\subsubsection{Axiomatic semantics} 

The proof system for equivalence is based on equational logic, together with axioms that describe the properties of Dirac notation. A full list of these axioms can be found in~\Cref{sec: full axioms}. The axioms cover fundamental aspects of linear spaces, as well as other structures like the tensor and inner products. For example, we have the absorption law for zero symbols:
\(X \cdot \mathbf{0} = \mathbf{0},\)
and the bilinearity of the dot product:
\[
(a.X) \cdot Y = a \cdot (X \cdot Y), \quad X \cdot (Y_1 + Y_2) = X \cdot Y_1 + X \cdot Y_2, 
\]
\[
X \cdot (a.Y) = a \cdot (X \cdot Y), \quad (X_1 + X_2) \cdot Y = X_1 \cdot Y + X_2 \cdot Y.
\]

As mentioned in the introduction, a subset \( E \) of these axioms cannot be decided by term rewriting alone. The axioms in \( E \) include:
\[
\begin{aligned}
    \text{AC-equivalence} &\quad \text{e.g.,} \quad X + Y = Y + X, \quad (X + Y) + Z = X + (Y + Z), \\
    \alpha\text{-equivalence} &\quad \lambda x . A = \lambda y . A\{x/y\}, \\
    \text{SUM-SWAP} &\quad \sum_{i \in s_1} \sum_{j \in s_2} A = \sum_{j \in s_2} \sum_{i \in s_1} A, \\
    \text{scalar theories} &\quad \text{e.g.,} \quad a + 0 = a, \quad a \times (b + c) = a \times b + a \times c.
\end{aligned}
\]
The scalar theories are treated separately as a module and are not considered in this work. In the implementation, we use the Mathematica kernel to decide scalar equivalences.
These equational axioms provide an operable theory for the proof automation algorithm. Denotational semantics can be seen as one model for this theory, meaning that equivalences derived from the axioms always imply equivalence in the interpretations.
\begin{lemma}
    For all well-formed contexts \( E[\Gamma] \) and terms \( e_1, e_2 \), if \( \vdash e_1 = e_2 \), then \( \sem{e_1} = \sem{e_2} \).
\end{lemma}
\begin{proof}
    This follows directly from checking all cases.
\end{proof}

Thus, the axioms are sound with respect to denotational semantics. However, the reverse does not hold: there exist equivalences in denotational semantics that cannot be captured by these axioms. Nevertheless, our work focuses on solving practical examples, which are fully covered by the axioms in the experiments.

To conclude this section, we demonstrate the formalization of the symbols used in the motivating example.
\begin{example}[Formalizing the Motivating Example]
    \label{ex: formalizing motivating}
    Definitions and assumptions in the environment \( E \) are formalized as follows:
    \begin{align*}
        & \text{TPO} && := \mu T_1. \mu T_2. \lambda O : \OType(T_1, T_2). \sum_{i \in \mathbf{U}(T_1)} \sum_{j \in \mathbf{U}(T_2)} \bra{i} O \ket{j} . \ket{j}\bra{i} \\
        & &&\quad : \forall T_1. \forall T_2. \OType(T_1, T_2) \to \OType(T_2, T_1); \\
        &\text{phi} &&:= \mu T. \sum_{i \in \mathbf{U}(T)} \sum_{j \in \mathbf{U}(T)} \ket{(i, j)} : \forall T.\KType(T \times T); \\
        & T && : \Index; \\
        & M && : \OType(T, T).
    \end{align*}
    The symbol \( \text{TPO} \) represents the transpose of an operator, polymorphic on the Hilbert spaces \( T_1 \) and \( T_2 \). The symbol \( \text{phi} \) takes the index \( T \) and defines the maximally entangled states, summing over all basis elements in \( T \), as indicated by the universal set \( \mathbf{U}(T) \).
    With the assumption of the index \( T \) and operator \( M \), we can express the equivalence in the non-labelled version as:
    \[
    (\textrm{M} \otimes \mathbf{1}_\mathcal{O}(\textrm{T})) \cdot (\textrm{phi T}) = (\mathbf{1}_\mathcal{O}(\textrm{T}) \otimes (\textrm{TPO T T M})) \cdot (\textrm{phi T}).
    \]
\end{example}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Algorithm for Deciding Dirac Notation Equations}
\label{sec: decide}

We utilize the term rewriting technique to decide the equivalence of Dirac notation, based on its axiomatic semantics. The process involves normalizing two terms and checking whether they have identical syntax. This normalization is achieved through matching and substitution in universal algebra, using a set of predefined rewriting rules.

As mentioned in the semantics section, the axioms in \( E \) cannot be fully decided through term rewriting. DiracDec decides \( E \) by examining all possible permutations in the rewriting result. In this work, we introduce a more efficient approach by incorporating sorting algorithms into the normalization procedure. 

The normalization procedure consists of the following steps.
\begin{enumerate}
    \item \textbf{First Rewritings}: Expand definitions and simplify expressions.
    \item \textbf{Variable Expansion}: Consider scalar expressions to ensure completeness.
    \item \textbf{Second Rewritings}: Normalize terms modulo \( E \).
    \item \textbf{Sorting Without Bound Variables}: Normalize AC-equivalence.
    \item \textbf{Swap Successive Summations}: Normalize SUM-SWAP equivalences.
    \item \textbf{De Bruijn Normalization}: Normalize \( \alpha \)-equivalence.
\end{enumerate}

\subsection{Normalization Modulo \( E \) by Term Rewriting}

Term rewriting rules, represented as \( l \ \reduce\ r \), are applied recursively to normalize terms. In each step, subterms matching the left-hand side \( l \) of a rule are replaced with the corresponding right-hand side \( r \). The procedure terminates when no further rewritings can be made.
A comprehensive list of rewriting rules can be found in~\Cref{sec: rewriting rules}. Below are some key examples to illustrate the design:

One of our optimizations is using functions with indefinite arities. 
Therefore, we use a flattening rule to handle associativity with AC symbols:
\[
a_1 + \cdots + (b_1 + \cdots + b_m) + \cdots + a_n \ \reduce\ a_1 + \cdots + b_1 + \cdots + b_m + \cdots + a_n.
\]
Commutativity is handled later in the sorting step. Many of the rewriting rules are directly derived from the equational axioms, such as:
\begin{align*}
    & \textrm{(R-DOT6)} && \bra{s} \cdot \ket{t} \ \reduce\  \delta_{s, t}, \\
    & \textrm{(R-DELTA0)} && \delta_{s, s} \ \reduce\  1, \\
    & \textrm{(R-MULK1)} && O : \OType(\sigma, \tau) \Rightarrow O \cdot \mathbf{0}_{\KType(\tau)} \ \reduce\  \mathbf{0}_{\KType(\sigma)}, \\
    & \textrm{(R-MULK11)} && (O_1 \otimes O_2) \cdot (K_1 \otimes K_2) \ \reduce\  (O_1 \cdot K_1) \otimes (O_2 \cdot K_2).
\end{align*}
Some of these directions are obvious. For example, (R-DOT6) states that the inner product of two basis vectors is reduced to a delta expression, and (R-DELTA0) transforms a delta function on identical basis to a scalar \( 1 \). The rule (R-MULK1) reflects the axiom that multiplying a zero vector results in zero. This rule is conditional on typing, which is checked during rewriting. Some rules, like (R-MULK11), require a deeper understanding, such as the preference for tensor products over multiplication.

As a reference, the term rewriting system in DiracDec has been proven complete for all axioms, except for the sum symbol. The completeness result is derived from checking the confluence and termination of the system. Our rewriting rules are translations from DiracDec into the typed and abstract language, ensuring that the corresponding symbols in our system are also complete.

We also have additional rules that handle summations. For example:
\begin{align*}
    & \quad i \text{ free in } t \Rightarrow \sum_{i \in \mathbf{U}(\sigma)} \sum_{k_1 \in s_1} \cdots \sum_{k_n \in s_n} (\delta_{i, t}.A) \ \reduce\  \sum_{k_1 \in s_1} \cdots \sum_{k_n \in s_n} A\{i/t\}, \\
    & \quad \left( \sum_{i \in M} B \right) \cdot K \ \reduce\  \sum_{i \in M} (B \cdot K).
\end{align*}
The first rule eliminates delta expressions in summations, while the second rule pushes summations outside of inner products. While there is no guarantee of completeness for these rules, they work effectively in practice.

\subsubsection{Variable Expansion}
One important technique, revealed in the DiracDec work, is the expansion of variables, which is critical for proofs involving summation. For example:
\[
\frac{E[\Gamma] \vdash K : \KType(\sigma)}{E[\Gamma] \vdash K \ \reduce\ \sum_{i \in \mathbf{U}(\sigma)}(\bra{i} \cdot K).\ket{i}} \quad \quad
\frac{E[\Gamma] \vdash B : \BType(\sigma)}{E[\Gamma] \vdash B \ \reduce\ \sum_{i \in \mathbf{U}(\sigma)}(B \cdot \ket{i}).\bra{i}},
\]
\[
\frac{E[\Gamma] \vdash O : \OType(\sigma, \tau)}{E[\Gamma] \vdash O \ \reduce\ \sum_{i \in \mathbf{U}(\sigma)} \sum_{j \in \mathbf{U}(\tau)}(\bra{i} \cdot O \cdot \ket{j}).(\ket{i} \cdot \bra{j})}.
\]
These rules transform variables into their symbolic summations based on their decomposition over the basis. 
The rules are not terminating, therefore is applied recrusively once in the second step called \textit{variable expansion}.
Nevertheless, we have found that applying the expansion only once for all variables is sufficient for normalization.
\begin{lemma}
    Let \( \textrm{expand}(e) \) denote the result of expanding all variables in \( e \) once. For all well-typed terms \( e \) in \( E[\Gamma] \), \( \textrm{expand}(\textrm{expand}(e)) \) and \( \textrm{expand}(e) \) have the same normal form.
\end{lemma}
\begin{proof}
    Expanding a ket variable twice, for example, results in the following transformation:
    \[
    \sum_{i \in \mathbf{U}(\sigma)} (\bra{i} \cdot \sum_{j \in \mathbf{U}(\sigma)} (\bra{j} \cdot K) \cdot \ket{j}) \cdot \ket{i} \ \reduce\  \sum_{i \in \mathbf{U}(\sigma)} \sum_{j \in \mathbf{U}(\sigma)} (\bra{j} \cdot K \cdot \braket{i|j}) \cdot \ket{i},
    \]
    where the delta symbol elimination rule returns the term to its original form. The same holds for bra and operator terms.
\end{proof}



\subsection{Deciding Equational Theory \( E \)}

In the Mathematica implementation of DiracDec, the equational theory \( E \) is decided using unification, which attempts to find a substitution for the summation bound variables that makes two expressions syntactically equivalent. This unification process iterates through all permutations of AC symbol arguments, and its complexity is factorial in the maximum number of AC symbol arguments.

As the first improvement, we check \( \alpha \)-equivalence using the de Bruijn index~\cite{deBruijn1972lambda}, which replaces references to bound variable names with the distance from the lambda abstraction to the variable. For instance, the nominal lambda abstraction \( \lambda x. x \) is transformed into \( \lambda . 0 \), while \( \lambda x. \lambda y. (x\ (y\ x)) \) is transformed into \( \lambda.\lambda. (1\ (0\ 1)) \). This transformation into the de Bruijn index is performed as the final step in the normalization process to check equivalence between terms with different bound variable names.

The remaining axioms, such as AC-equivalence and SUM-SWAP, assert equivalence under permutations. A standard approach for deciding such equivalences is to normalize terms by sorting in a predefined order. For example, given the dictionary order \( a < b < c \), the term \( b + c + a \) (and any other AC-equivalent term) is normalized into \( a + b + c \). However, in our setting, two intertwined difficulties arise: how to assign an order to all terms in the language, and how to simultaneously sort for both axioms.

Consider the following two equivalent terms:
\[
\sum_{i \in s_1} \sum_{j \in s_2} \bra{i} A \ket{j} \times \bra{j} B \ket{i}
= 
\sum_{i \in s_2} \sum_{j \in s_1} \bra{i} B \ket{j} \times \bra{j} A \ket{i}
\]
While these two terms are equivalent, directly sorting the elements of scalar multiplication using lexical order does not yield the same form.

To address this issue, we propose an algorithm that sorts terms without considering bound variables. The key observation is that in a successive sum expression \( \sum_{i \in s_1} \cdots \sum_{j \in s_n} A \), the names and order of the bound variables \( i, \dots, j \) can be freely permuted. Therefore, all bound variables should be treated uniformly during sorting, and the order of summation can then be determined based on the position of the bound variables.

In the example above, we first ignore the bound variables and sort the sum body into \( \bra{\bullet} A \ket{\bullet} \times \bra{\bullet} B \ket{\bullet} \). Then, we swap the summations such that the bound variable at the first \( \bullet \) position appears at the outermost position. The results will have the same de Bruijn normal form, namely \( \sum_{s_1} \sum_{s_2} \bra{\$1} A \ket{\$0} \times \bra{\$0} B \ket{\$1} \).


To describe the algorithm in the following, we introduce two key notations. For a term \( e = f(a_1, a_2, \dots, a_n) \), \( \textrm{head}(e) \) denotes the function symbol \( f \), while \( \textrm{arg}(e, i) \) refers to the \( i \)-th argument \( a_i \) of the term. In this context, variables and constants are treated as functions with zero arguments.



\begin{definition}[Order Without Bound Variables]
Let \( \mathcal{B} \) represent the set of bound variables, with the assumption that all bound variables are unique. We also assume that a total order exists over all symbols. The relation \( e_1 =_\mathcal{B} e_2 \) holds if:
\begin{itemize}
    \item \( \textrm{head}(e_1) = \textrm{head}(e_2) \), and for all \( i \), \( \textrm{arg}(e_1, i) =_\mathcal{B} \textrm{arg}(e_2, i) \), or
    \item \( e_1 \in \mathcal{B} \) and \(e_2 \in \mathcal{B}\).
\end{itemize}

The relation \( e_1 <_\mathcal{B} e_2 \) holds between two terms if:
\begin{itemize}
    \item $e_1 \notin \mathcal{B}$ and $e_2 \in \mathcal{B}$, or
    \item $head(e_1) < head(e_2)$, or
    \item $head(e_1) = head(e_2)$, and there exists $n$ with $arg(e_1, n) <_\mathcal{B} arg(e_2, n)$, where $arg(e_1, i) =_\mathcal{B} arg(e_2, i)$ for all $i < n$.
\end{itemize}
\end{definition}
It can be shown that \( e_1 =_\mathcal{B} e_2 \) if and only if neither \( e_1 <_\mathcal{B} e_2 \) nor \( e_2 <_\mathcal{B} e_1 \) holds. The purpose of this ordering is to compare function symbols in a top-down manner while ignoring bound variables. The sorted order enables normalization of terms in terms of AC equivalence.
\begin{definition}[Sort Transformation]
    For a term $e$ with bound variable set $\mathcal{B}$,
    The sort transformation sort(e) is defined as
    \begin{itemize}
        \item $e$, if $e$ is a variable or constant;
        \item $\lambda x:T. \textrm{sort}(e')$, if $e \equiv \lambda x : T. e'$;
        \item $\mu x. \textrm{sort}(e')$, if $e \equiv \mu x. \textrm{sort}(e')$; or
        \item $f(\textrm{sort}(a_1), \cdots, \textrm{sort}(a_n))$, if $e \equiv f(a_1, \cdots, a_n)$. If $f$ is an AC symbol, then the order of sort($a_i$) is sorted ascendingly according to $<_\mathcal{B}$.
    \end{itemize}
\end{definition}

After sorting, the next step is the \textit{swap transformation}, which arranges successive summations based on the order of bound variables.
\begin{definition}[Swap Transformation]
For a term \( e \) with a sorting result \( \textrm{sort}(e) \), the swap transformation proceeds by ordering all bound variables according to their first appearances, except in function definitions \( \lambda x \) and \( \mu x \). The swap transformation then reorders the successive summations accordingly.
\end{definition}

The algorithm that applies the sort and swap transformations, followed by de Bruijn normalization, successfully handles all equivalences in our benchmark. We formalize the completeness of this transformation in the following conjecture:

\begin{conjecture}[Completeness of Transformation]
    For any two terms \( e_1 \) and \( e_2 \) that are equivalent under AC equivalence, SUM-SWAP, and \( \alpha \)-equivalence, they will have the same form after sort, swap, and de Bruijn transformations.
\end{conjecture}



% The order depends on there occurances in the last sorting result. If no occurance, then the order will depend on the set (for sum) and the type (for lambda abstraction only).

%%%%%%%%%%%%%%%%%%%%%%%


% The idea is to assign an order to terms, which is independent on the bound variables. Because we can have terms with nested AC symbols.

Lastly, we can prove that the equivalence established by this normalization procedure is sound with respect to the semantics.

\begin{theorem}[Soundness]
    For any well-formed context \( E[\Gamma] \) and well-typed expressions \( e_1 \) and \( e_2 \), if  $e_1$ and $e_2$ have the same normal form, then \( \sem{e_1} = \sem{e_2} \).
\end{theorem}

\begin{proof}
    The soundness of the term rewriting procedure follows from the fact that each rewriting rule preserves equivalence. Furthermore, the operations in the sort and swap transformations respect the AC-equivalence and SUM-SWAP axioms. Finally, the de Bruijn normalization ensures soundness for \( \alpha \)-equivalence.
\end{proof}



% Labelled Dirac Notation

\section{Labelled Dirac Notation}
\label{sec: labelled}
Labelled Dirac notation uses register names to indicate the quantum system of vectors and operators. This allows us to express and reason aboud the states and operations locally, without referring to the whole system. For instance, assume $Q$ and $R$ are two registers, we have
\[
    M_Q \cdot \ket{\Phi}_{(Q, R)} = ((M \otimes I) \cdot \ket{\Phi})_{(Q, R)}.
\]
On the left hand side, the state of two subsystems is $\ket{\Phi}$, and we apply quantum operation $M$ on the system $Q$. It is equivalent to extend the operation using identity operators on other subsystems (i.e. the cylinder extension), and consider the application in the whole system.


In this section, we introduce the language and typing of registers and labelled Dirac notation, and demonstrate how to transform the equivalence problem into that for the Dirac notation studied above.
The first new notion is quantum registers, and we assume they are constructed from a set $\cR$.
\begin{definition}[quantum registers]
  \begin{align*}
    R ::= r\in\cR \mid (R, R).
  \end{align*}
\end{definition}

Registers can be composed by pairs of $(R, R)$, and this structure corresponds to the structure of tensor product spaces in Dirac notation.
To reason about the registers, we define their variable set as the enumeration of all register symbols involved.

\begin{definition}[register variable set]
The variable set of a register is defined inductively by:
\begin{itemize}
    \item $\var(R) = \{r\}$, if $R\equiv r$; or
    \item $\var(R) = \var(R_1) \cup\var(R_2)$, if $R\equiv (R_1,R_2)$.
\end{itemize}
\end{definition}

% \textbf{Remark: } Set operations: $\cup$ for union; $\cap$ for intersection; $\setminus$ for difference. So,
% % \begin{itemize}
% $ S_1 \cap S_2 \equiv S_1 \cup S_2 \setminus (S_1 \setminus S_2) \setminus (S_2 \setminus S_1) $.
% \end{itemize}

% The labelled Dirac notation is an extension on the existing type and syntax.
\begin{definition}[labelled Dirac notation]
  The \textbf{labelled Dirac notation} includes all Dirac notation symbols and the generators defined below.
  Here, $s\subseteq \cR$ is a register variable set.
  \begin{align*}
    T & ::= \DType(s,s) \mid \mathsf{Reg}(\sigma) \\
    e & ::= R \mid |i\>_r \mid {}_r\<i| \mid e_R \mid e_{R;R} \mid
    e \otimes e \otimes \cdots \otimes e \mid e \cdot e
  \end{align*}
\end{definition}
$\DType(s_1, s_2)$ is the unified type for all labelled Dirac notation, where $s_1$ indicates the codomain systems and $s_2$ indicates the domain systems. For instance, labelled ket has type $\DType(s_1, \emptyset)$, and labelled bra has type $\DType(\emptyset, s_2)$.
$\reg(\sigma)$ are types for registers $R$, and the index $\sigma$ indicates the type of Hilbert space represented by the register.
Terms also include the labelled notation $e_R$ for bra, ket and $e_{R;R}$ for operators. We introduce new dot and tensor product symbols for labelled Dirac notation. In labelled Dirac notation, the structure of tensor product does not matter, therefore $\otimes$ is an AC symbol.
Following the unified type $\DType(s,s)$, all kinds of multiplications are represented by the same dot product $e \cdot e$.
Finally, $\ket{i}_r$ and ${}_r\bra{i}$ are labelled basis for the normal form of labelled Dirac notation, where $r$ are registers symbols in $\mathcal{R}$. 

\subsubsection{Typing rules}
Some typing rules are introduced here.
The rule for $\DType(s_1, s_2)$ requires that all registers in variable set $s_1$ and $s_2$ are well-typed.
The rule for $K_R$ demonstrates how a register label is added to the Dirac notation, and the rule for $D^\dagger$ shows that labelled Dirac notation also have symbols for calculation, such as the adjoint.
\[
    \frac{E[\Gamma] \vdash  \sigma : \Index}{E[\Gamma] \vdash \reg(\sigma) : \Type}
    \qquad
    \frac{E[\Gamma] \vdash r : \reg(\sigma_r) \text{ for all $r$ in $s_1$ and $s_2$} }{E[\Gamma] \vdash \DType(s_1, s_2) : \textsf{Type}} 
\]
\[
    \frac{E[\Gamma] \vdash R : \reg(\sigma)\qquad E[\Gamma] \vdash K : \KType(\sigma)}{E[\Gamma] \vdash K_R : \DType(\var R, \emptyset)}
    \qquad
    \frac{E[\Gamma] \vdash D : \DType(s_1,s_2)}{E[\Gamma] \vdash D^\dagger : \DType(s_2,s_1)}
\]
The dot and the tensor product symbols are different from those in unlabelled Dirac notation. Since the goal of labels is to replace the order and structure of tensor products by the reference to registers, the tensor product becomes an AC symbol. The typing still checks whether the component subsystems are disjoint with each other.
\[
    \frac{
        E[\Gamma] \vdash D_i : \DType(s_i,s_i') \qquad
        \bigcap_i s_i = \emptyset \qquad
        \bigcap_i s_i' = \emptyset
    }
    {E[\Gamma] \vdash D_1 \otimes \cdots \otimes D_i : \DType(\bigcup_i s_i, \bigcup_i s_i')}.
\]
As for the dot product, the disjointness is considered except registers contracted by multiplication.
\[
    \qquad
    \frac{
        \begin{aligned}
            E[\Gamma] \vdash D_1 : \DType(s_1,s_1') \\
            E[\Gamma] \vdash D_2 : \DType(s_2,s_2')
        \end{aligned}
        \qquad 
        \begin{aligned}
            s_1 \cap s_2 \backslash s_1' = \emptyset \\
            s_2' \cap s_1' \backslash s_2 = \emptyset
        \end{aligned}
    }
    {E[\Gamma] \vdash D_1\cdot D_2 : \DType(s_1 \cup (s_2\backslash s_1'), s_2' \cup (s_1'\backslash s_2))}.
\]

\subsubsection{Normalization}
The normalization procedure of Dirac notation is extended to check equivalence with labels.
We add rules to the term rewriting system, which in general try to represent labelled Dirac notation with labelled basis and scalar coefficients. The first step is the label elimination. Take operator as an example:
\begin{align*}
    & O_{R,R'} \ \reduce\ \sum_{i_{r_1}\in\bU(\sigma_{r_1})}\cdots \sum_{i_{r_n}\in\bU(\sigma_{r_n})}
    \sum_{i_{r'_1}\in\bU(\sigma_{r'_1})}\cdots \sum_{i_{r'_{n'}}\in\bU(\sigma_{r'_{n'}})} \\
    & \qquad (\<i_R|\cdot O\cdot |i_{R'}\>).(|i_{r_1}\>_{r_i}\otimes\cdots\otimes|i_{r_n}\>_{r_n} \otimes {}_{r'_1}\<i_{r'_1}|\otimes\cdots\otimes{}_{r'_{n'}}\<i_{r'_{n'}}|).
\end{align*}
The rules for $e_R$ (ket and bra) are similar. This step reduces all labelled terms $e_R$ or $e_{R;R}$.
Other symbols on labelled Dirac notation are also reduced by rules like $(D_1 \cdot D_2)^\dagger \ \reduce\ D_2^\dagger \cdot D_1^\dagger$.
The final step operates on sum and dot product. They will lift summation to the outside, and eliminate the bra-ket pairs whenever possible.
\begin{align*}
    & \textrm{(R-SUM-PUSHD0)}
    && X_1 \otimes \cdots (\sum_{i \in M} D) \cdots \otimes X_2\ \reduce\ \sum_{i \in M} (X_1 \otimes \cdots D \cdots \otimes X_n) \\
    % %
    % & \textrm{(R-SUM-PUSHD1)}
    % && (\sum_{i \in M} D_1) \cdot D_2 \ \reduce\ \sum_{i \in M} (D_1 \cdot D_2) \\
    %
    & \textrm{(R-L-SORT0)}
    && A : \DType(s_1, s_2), B : \DType(s_1', s_2'), s_2 \cap s_1'=\emptyset \Rightarrow A \cdot B \ \reduce\ A \otimes B \\
    %
    & \textrm{(R-L-SORT1)}
    && {}_r\bra{i}\cdot\ket{j}_r \ \reduce\ \delta_{i, j} \\
    %
    & \textrm{(R-L-SORT2)}
    && {}_r\bra{i}\cdot(Y_1 \otimes \cdots \otimes \ket{j}_r \otimes \cdots \otimes Y_m) \ \reduce\ \delta_{i, j}.(Y_1  \otimes \cdots \otimes Y_m)
    %
\end{align*}
% These rules are added to the rewriting system in~\Cref{sec: decide} and executed together.
In the end, if there are no variables of $\DType(s_1, s_2)$, the expression will be reduced to the addition of big operator sum, and each sum body is labelled basis with Dirac notation scalar coefficients:
\[
    \sum_{i}\cdots\sum_{j} a_1 . (\ket{i}_{p} \otimes \cdots \otimes \bra{j}_{q})
    + \cdots +
    \sum_{k}\cdots\sum_{l} a_m . (\ket{k}_{r} \otimes \cdots \otimes \bra{l}_{s})
\]
In this stage, we only need to check the scalars to decide the equivalence of labelled Dirac notation.

% \begin{lemma}[normal form]
%     \label{lem: labelled normal form}
%     For a well-typed term $e$ in $E[\Gamma]$, if $e$ does not contain variables of $\DType(s_1, s_2)$ type, the normal form of $e$ will be
%     \[
%     \sum_{i}\cdots\sum_{j} a_1 . (\ket{i}_{p} \otimes \cdots \otimes \bra{j}_{q})
%     + \cdots +
%     \sum_{k}\cdots\sum_{l} a_m . (\ket{k}_{r} \otimes \cdots \otimes \bra{l}_{s})
%     \]
%     Where $a_i$ are scalar typed Dirac notation.
% \end{lemma}
% \begin{proof}
%     Labelled Dirac notation of $e_R$, $e_R;R$, 
% \end{proof}



