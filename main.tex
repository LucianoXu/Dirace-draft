% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}


% \usepackage[utf8]{inputenc}
% \usepackage[margin=0.8in]{geometry}




\usepackage{color}
\usepackage{amsmath}
%\usepackage{amssymb}
\usepackage{graphicx}
% \usepackage{amsthm}
\usepackage{stmaryrd}
\usepackage[all]{xy}
\usepackage{multirow}
\usepackage{paralist}
\usepackage{hhline}
\usepackage{bm}
\usepackage{longtable}
\usepackage{makecell}
\usepackage{mdframed}

\usepackage{wasysym}
\usepackage{extarrows}
\usepackage{tikz}

% add new commands for comments here
\newcommand{\yx}[1]{\textit{\color{blue}[YX] : #1}}
\newcommand{\lz}[1]{\textit{\color{red}[LZ] : #1}}

\newcommand{\modify}[1]{{\color{red}#1}}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{stmaryrd}
\usepackage{hyperref}

\usepackage{braket}
\usepackage{cleveref}

\input{lstlisting}

\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}
\usetikzlibrary{trees}
\tikzstyle{arrow} = [thick,->,>=stealth]



\newenvironment{ruletable}[1]
{
    \begin{longtable}{cl}
    \caption{#1}\\
    \hline
    \textbf{Rule} & \textbf{Description} \\
    \hline
    \endfirsthead

    \hline
    \textbf{Rule} & \textbf{Description} \\
    \hline
    \endhead

    % \hline
    % \multicolumn{2}{r}{\textit{Continued on the next page}} \\
    \hline
    \endfoot

    \hline
    \endlastfoot
}
{
    \end{longtable}
}

% define C++ logo
\newcommand{\CC}{C\nolinebreak\hspace{-.05em}\raisebox{.4ex}{\tiny\bf +}\nolinebreak\hspace{-.10em}\raisebox{.4ex}{\tiny\bf +}}
\def\CC{{C\nolinebreak[4]\hspace{-.05em}\raisebox{.4ex}{\tiny\bf ++}}}


%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
\usepackage{color}
\renewcommand\UrlFont{\color{blue}\rmfamily}
\urlstyle{rm}
%
\begin{document}
%
\title{Dirace: Practical Proof Automation of Dirac Notation Equations}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %
% %\titlerunning{Abbreviated paper title}
% % If the paper title is too long for the running head, you can set
% % an abbreviated paper title here
% %
% \author{First Author\inst{1}\orcidID{0000-1111-2222-3333} \and
% Second Author\inst{2,3}\orcidID{1111-2222-3333-4444} \and
% Third Author\inst{3}\orcidID{2222--3333-4444-5555}}
% %
% \authorrunning{F. Author et al.}
% % First names are abbreviated in the running head.
% % If there are more than two authors, 'et al.' is used.
% %
% \institute{Princeton University, Princeton NJ 08544, USA \and
% Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany
% \email{lncs@springer.com}\\
% \url{http://www.springer.com/gp/computer-science/lncs} \and
% ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
% \email{\{abc,lncs\}@uni-heidelberg.de}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Dirac notation is a fundamental language in quantum computation and quantum information. Recently, the term rewriting system DiracDec~\cite{diracdec} was introduced to automate equational reasoning with Dirac notation, a critical yet time-intensive task. Building upon DiracDec, this work aims to develop a solver optimized for practical applications. Enhancements include an improved typing system, a simplified language and rewriting system, more efficient algorithms, and added support for labeled Dirac notation. Our solver, Dirace, is implemented in \CC\ with a Mathematica backend, demonstrating significant improvements in decision-making power and time efficiency.


% \keywords{First keyword  \and Second keyword \and Another keyword.}
\end{abstract}
%
%
%



%%%%%%%%%%%%%%%%
\newcommand*{\sem}[1]{{\llbracket #1 \rrbracket}}
\newcommand{\DiracDec}{\textsf{DiracDec}}

\newcommand{\reduce}{\triangleright}

\newcommand{\Sort}{\mathsf{Sort}}
\newcommand{\WF}{\mathcal{WF}}

\newcommand{\Index}{\mathsf{Index}}
\newcommand{\Type}{\mathsf{Type}}
\newcommand{\Basis}{\mathsf{Basis}}

\newcommand{\SType}{\mathcal{S}}
\newcommand{\KType}{\mathcal{K}}
\newcommand{\BType}{\mathcal{B}}
\newcommand{\OType}{\mathcal{O}}
\newcommand{\SET}{\mathsf{Set}}

\newcommand{\ZEROK}{\mathbf{0}_\mathcal{K}}
\newcommand{\ZEROB}{\mathbf{0}_\mathcal{B}}
\newcommand{\ZEROO}{\mathbf{0}_\mathcal{O}}

\newcommand{\PAIR}{\mathsf{PAIR}}

\newcommand{\ZERO}{\mathsf{0}}
\newcommand{\ONE}{\mathsf{1}}
\newcommand{\ADDS}{\mathsf{ADDS}}
\newcommand{\ADD}{\mathsf{ADD}}
\newcommand{\MULS}{\mathsf{MULS}}
\newcommand{\MUL}{\mathsf{MUL}}
\newcommand{\CONJ}{\mathsf{CONJ}}
\newcommand{\CJG}{\mathsf{CJG}}
\newcommand{\ADJ}{\mathsf{ADJ}}
\newcommand{\DELTA}{\mathsf{DELTA}}
\newcommand{\DOT}{\mathsf{DOT}}
\newcommand{\SCR}{\mathsf{SCR}}
\newcommand{\TSR}{\mathsf{TSR}}
\newcommand{\KET}{\mathsf{KET}}
\newcommand{\BRA}{\mathsf{BRA}}
\newcommand{\ONEO}{\mathbf{1}_\mathcal{O}}
\newcommand{\OUTER}{\mathsf{OUTER}}
\newcommand{\MULK}{\mathsf{MULK}}
\newcommand{\MULB}{\mathsf{MULB}}
\newcommand{\MULO}{\mathsf{MULO}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

In 1939, Dirac introduced his notation for quantum mechanics~\cite{dirac1939new}, designed to represent linear algebraic formulas in a compact and convenient form. For example, the expression \( a\ket{\psi} + b\ket{\phi} \) represents the superposition of two quantum states, \( \ket{\psi} \) and \( \ket{\phi} \). Today, Dirac notation is widely accepted as the standard language in quantum computation and quantum information. Its reasoning forms the foundation of research and applications, much like boolean and integer logic do in classical computer science.

In quantum algorithm formalizations and quantum programming languages, Dirac notation is frequently used in equational proofs, which are critical, repetitive, and often time-intensive. These notations also play a key role in defining program states, operations, and assertions in quantum programming languages. To automate the verification of these programs, we need tools that can simplify and check the equivalence of preconditions. However, unlike the well-established SAT and SMT solvers for classical logic, a practical solver for Dirac notation equivalence remains an unmet need, creating a barrier for progress in several fields.

Recently, Xu et al.~\cite{diracdec} proposed a theory for deciding the equivalence of Dirac notation, alongside a prototype implementation in Mathematica called DiracDec. They demonstrated that the equivalence of basic Dirac notation is decidable. Their algorithm, based on a pure term rewriting system, has been proven to be confluent and terminating. Despite this, there remains a gap between DiracDec and a practical solver for Dirac notation equivalence.

One challenge is the efficiency of the algorithm when dealing with equivalences beyond the scope of term rewriting. DiracDec decides the entire equational theory by rewriting modulo \( E \), where \( E \) represents a set of axioms that cannot be decided by normalization alone, such as the associativity and commutativity (AC) of certain function symbols. DiracDec uses a direct but inefficient algorithm to decide these axioms, which searches through all possible permutations and exhibits factorial complexity. This inefficiency becomes particularly evident in "computational examples" containing many AC symbols, which are time-consuming to process.

Usability is another area where DiracDec falls short. It does not support labelled Dirac notation, which uses registers to denote subsystems and express states locally. Additionally, DiracDec's typing system only does not provide context for variable typing assumptions or the definition of symbols, which are required in practical scenarios. To avoid type checking during term rewriting, DiracDec separates symbols (e.g., multiplication) for different types, leading to unnecessary complexity. Moreover, integrating the Mathematica implementation into other projects as a solver is challenging.

The system design of DiracDec reflects a trade-off between simplicity and efficiency. While the simplicity of term rewriting allows for strong theoretical results, it limits optimization opportunities. Building on DiracDec, this work aims to develop a practical solver. We transform the term rewriting system into a hybrid algorithm, overcoming the challenges mentioned above. Our main technical contributions are:
\begin{itemize}
    \item An efficient algorithm for deciding the equational theories in \( E \), based on equivalence checking through normalization, with the normal form for \( E \) being obtained via sorting.
    \item Support for constant register labels, and reducing the equivalence decision of labelled Dirac notation to the unlabelled case.
    \item A more user-friendly \CC\ solver, Dirace, featuring an abstract language and typing system. We also support the definition of symbols (e.g., transpose and trace) using function syntax.
\end{itemize}

We evaluated Dirace against the DiracDec benchmark and new examples involving labelled Dirac notation. The results show significant improvements in both decidability and efficiency compared to DiracDec.

% Dirace successfully decides all the examples that are expressable in its language, including those failed by DiracDec because of complexity or insufficient decision power.


\section{Motivation and Preliminary}

An interesting property of quantum mechanics is that for two maximally entangled states, applying a quantum operator \( M \) to one subsystem is equivalent to applying \( M^T \) (the transpose of \( M \)) to the other subsystem. This relationship holds regardless of the spatial separation between the two systems, and it can be expressed as an equation in Dirac notation.
\begin{example}
    \label{ex: motivating}
    Let \( q \) and \( r \) represent two quantum systems in the Hilbert space \( \mathcal{H}_T \). Let \( M \) be a quantum operation acting on \( \mathcal{H}_T \), and let \( \ket{\Phi} = \sum_{i \in T} \ket{i} \otimes \ket{i} \) be the maximally entangled state. Then, we have the following equation:
    \[
    M_q \ket{\Phi}_{q; r} = M_r^T \ket{\Phi}_{q; r}.
    \]
\end{example}

In this equation, \( q \) and \( r \) are labels denoting the respective subsystems in the Dirac notation. To automate reasoning about such equations, we must formalize the language and develop a proof system to handle it.

\subsubsection{Dirac Notation}

Quantum states are represented as vectors in complex Hilbert spaces, and operations on these states are described by linear transformations. Dirac notation uses the ket \( \ket{i} \) and the bra \( \bra{i} \) to denote basis vectors in a Hilbert space and its dual space, respectively. These symbols can be composed together in various ways to form more complex expressions. The meaning of these compositions depends on the types of the operands involved.
For example, the inner product \( \braket{i|j} \) represents the scalar result of the dot product between \( \bra{i} \) and \( \ket{j} \), while the outer product \( \ket{i}\bra{j} \) represents an operator. Additionally, Dirac notation uses the tensor product symbol \( \otimes \) to describe the combined space of multiple quantum systems.

One of the key features of Dirac notation is its order-independent interpretation. This means that the composition of terms can be written without parentheses, as the interpretation is unaffected by the order of multiplication. For instance, the formula \( \bra{i}\ket{\phi}\bra{\psi}\ket{j} \) can be understood as:
\[
    \braket{i|\phi}\braket{\psi|j} = \bra{i} (\ket{\phi}\bra{\psi}) \ket{j},
\]
and these expressions are equivalent for all variables involved.

In practice, Dirac notation is often combined with other syntactic elements, such as the summation symbol \( \sum_{i \in S} A \), to enhance expressiveness. Furthermore, labelled Dirac notation, such as \( \ket{i}_q \otimes \ket{i}_r \), is used to denote quantum systems in consideration, where subscripts (registers) are added to distinguish different subsystems.

\subsubsection{Universal Algebra}
We use universal algebra and equational logic to formally represent Dirac notation and the reasoning procedure. A universal algebra defines a signature of function symbols, with terms constructed from constants, variables, and function applications. 
Other basic concepts like substitution of variables or pattern matching are also defined.
In our case of Dirac notation, the signature consists of constructors and operations like $\ket{i}$ or $A \otimes B$.
The reasoning process is guided by equational logic, which defines an equivalence relation that is compatible with substitution and term construction. This relation formalizes the intuitive concept of equivalence in algebra.



\section{Language, Typing and Semantics}
The first step is to formalize the language for Dirac notation. In DiracDec, the language has a concrete design, where the same syntax for different types corresponds to distinct symbols. Our goal is to transition from this concrete design to a more abstract one, which aligns more closely with the conventional Dirac notation we use and simplifies the term rewriting system.

To achieve this, we organize our language into three layers: the index, the type, and the term. Terms represent concrete instances such as kets, bras, and operators, which will be typed and checked. The index represents classical data types and appears in type expressions to differentiate between various Hilbert spaces and sets.

\begin{definition}[Index Syntax]
    The syntax for type indices is:
    \begin{align*}
        \sigma ::=\ & x \mid \sigma_1 \times \sigma_2.
    \end{align*}
\end{definition}
Here, \( x \) is a variable, and \( \sigma_1 \times \sigma_2 \) represents the product type for tensor product spaces or Cartesian product sets.

\begin{definition}[Type Syntax]
    The syntax for Dirac notation types is:
    \begin{align*}
        T ::=\ & \Basis(\sigma) \mid \SType \mid \KType(\sigma) \mid \BType(\sigma) \mid \OType(\sigma_1, \sigma_2) \mid T_1 \to T_2 \mid \forall x.T \mid \SET(\sigma).
    \end{align*}
\end{definition}
\( \Basis(\sigma) \) denotes the type for basis elements in the index \( \sigma \).
\( \SType \) represents scalars, while \( \KType(\sigma) \) and \( \BType(\sigma) \) refer to ket and bra types in the Hilbert space \( \sigma \), respectively.
\( \OType(\sigma_1, \sigma_2) \) represents linear operators with \( \sigma_2 \) as the domain and \( \sigma_1 \) as the codomain.
\( \SET(\sigma) \) refers to the type of subsets of \( \sigma \), used to denote the values of bound variables in summations.
The remaining two constructs define function types: \( T_1 \to T_2 \) represents normal functions that take a \( T_1 \)-type argument and return a \( T_2 \)-type term, while \( \forall x. T \) represents index functions that take an index argument \( x \) and produce a \( T \)-type term, which may depend on \( x \).
Index functions are essential for defining polymorphic transformations across Hilbert spaces.


\begin{definition}[Term Syntax]
    The syntax for Dirac notation terms is:
    \begin{align*}
        e ::=\ & x \mid \lambda x : T.e \mid \mu x.e \mid e_1\ e_2 \mid (e_1, e_2) \\
        & |\ 0 \mid 1 \mid \ADDS(e_1, \cdots, e_n) \mid e_1 \times \cdots \times e_n \mid e^* \mid \delta_{e_1, e_2} \mid \DOT(e_1, e_2) \\
        & |\ \ZEROK(\sigma) \mid \ZEROB(\sigma) \mid \ZEROO(\sigma_1, \sigma_2) \mid \ONEO(\sigma) \\
        & |\ \ket{e} \mid \bra{t} \mid e^\dagger \mid e_1.e_2 \mid \ADD(e_1, \cdots, e_n) \mid e_1 \otimes e_2 \\
        & |\ \MULK(e_1, e_2) \mid \MULB(e_1, e_2) \mid \OUTER(e_1, e_2) \mid \MULO(e_1, e_2) \\
        & |\ \mathbf{U}(\sigma) \mid e_1 \star e_2 \mid \sum_{e_1} e_2.
    \end{align*}
\end{definition}
The terms above are explained in order:
\( \lambda x : T.e \) represents the abstraction for normal functions, and \( \mu x.e \) represents the abstraction for index functions.
\( e_1\ e_2 \) denotes function application.
\( (e_1, e_2) \) is the basis pair for product types.
The constants \( 0 \), \( 1 \), \( \ADDS \), \( e_1 \times \cdots \times e_n \), and \( e^* \) are symbols for scalars.
The next line includes constant symbols for kets, bras, and operators.
\( \ket{e} \) is a ket, \( \bra{t} \) is a bra, and \( e^\dagger \) denotes the conjugate transpose of \( e \).
\( e_1.e_2 \) represents scaling the term \( e_2 \) by scalar \( e_1 \).
\( \mathbf{U}(\sigma) \) denotes the universal set with index \( \sigma \).
\( e_1 \star e_2 \) represents the Cartesian product of \( e_1 \) and \( e_2 \).
\( \sum_{e_1} e_2 \) is the big operator sum, modeled by folding the function \( e_2 \) over the value set \( e_1 \). Typically, the sum's body is given by an abstraction. For convenience, we also use the notation \( \sum_{x \in s} X \) to represent \( \sum_{s} \lambda x : T . X \).
Additionally, \( \ADDS \) and \( \ADD \) are distinct AC symbols: \( \ADDS \) is used for scalar addition and \( \ADD \) for linear algebra addition.
There are five kinds of linear algebraic multiplications among kets, bras, and operators. These are encoded using five different symbols: \( \DOT \), \( \MULK \), \( \MULB \), \( \OUTER \), and \( \MULO \).

Compared to DiracDec, the symbols for addition, adjoint, scaling, and tensor products have been consolidated.
The multiplications are still kept separate due to their differing properties.
These operations are denoted as \( B \cdot K \), \( K_1 \cdot K_2 \), \( B_1 \cdot B_2 \), \( K \cdot B \), and \( O_1 \cdot O_2 \), respectively.




\subsection{Typing System}


The typing system is responsible for classifying terms within a proof system, using a context that specifies the types of variables and definitions. The context is divided into two components: the environment \( E \), which includes definitions and assumptions, and the context \( \Gamma \), which tracks bound variables. Both \( E \) and \( \Gamma \) consist of sequences of assumptions \( x : T \) or definitions \( x := t : T \).
\begin{definition}[Environment and Context]
    The syntax for \( E \) and \( \Gamma \) is:
    \begin{align*}
        E ::= &\ [] \mid E; x : \Index \mid E; x : T \mid E; x := t : T. \\
        \Gamma ::= &\ [] \mid \Gamma; x : \Index \mid \Gamma; x : T.
    \end{align*}
\end{definition}
Definitions refer to symbols that can be expanded or unfolded, and typically represent abstract concepts, such as transpose or trace in Dirac notation. Assumptions, on the other hand, define the types of variables, and variable assumptions are implicitly universally quantified in the case of equational proofs.

Type checking in our language involves maintaining a well-formed environment and context \( E[\Gamma] \). We say an expression \( t \) has type \( X \) in context \( E[\Gamma] \) if the typing judgment \( E[\Gamma] \vdash t : X \) can be proven through the rules in~\Cref{sec: full typing rules}. The well-formedness of the context \( \WF(E)[\Gamma] \) is built incrementally:
\[
    \frac{}{\WF([])[]}
    \qquad
    \frac{\WF(E)[] \qquad x \notin E}{\WF(E; x : \Index)[]}
    \qquad
    \frac{E[]\vdash t:T \qquad x \notin E}{\WF(E; x := t:T)[]}.
\]
Starting with an empty context, new index symbols can be introduced, and symbols with checked types can be defined. Typing judgments are then made inductively using the information from \( E[\Gamma] \). For instance, the rule \( x : \Index \in E[\Gamma] \) holds if \( E \) or \( \Gamma \) contains an assumption for \( x \).
And \(\KType(\sigma)\) is a valid type for kets, if the argument $\sigma$ is typed as an index.
\begin{gather*}
    \frac{\WF(E)[\Gamma] \qquad x : \Index \in E[\Gamma]}{E[\Gamma] \vdash x : \Index}
    \qquad
    \frac{E[\Gamma] \vdash \sigma : \Index}{E[\Gamma] \vdash \KType(\sigma) : \Type}
\end{gather*}

Terms are then typed accordingly.
For example, the ket \( \ket{t} \) will have the type \( \KType(\sigma) \) if \( t \) is a basis term of index \( \sigma \). Similarly, the inner product between a bra and a ket of the same index \( \sigma \) is typed as a scalar. It corresponds to the constraint of inner product that vectors should be from the same Hilbert space.
\begin{gather*}
    \frac{E[\Gamma]\vdash t : \Basis(\sigma)}{E[\Gamma] \vdash \ket{t} : \KType(\sigma)}
    \qquad
    \frac{E[\Gamma]\vdash B : \BType(\sigma) \qquad E[\Gamma]\vdash K : \KType(\sigma)}{E[\Gamma] \vdash B \cdot K : \SType}
\end{gather*}

The typing for functions and applications follows the standard practice. For example, the index function \( \mu x. t \) is typed with \( x \) as a bound variable of type \( \Index \), and the application \( (t\ u) \) has the type \( U\{x/u\} \), obtained by replacing \( x \) with the index instance \( u \).
\begin{gather*}
    \frac{E[\Gamma; x : T] \vdash t : U}{E[\Gamma] \vdash (\lambda x : T . t) : T \to U}
    \qquad
    \frac{E[\Gamma] \vdash t:U \to T \qquad E[\Gamma] \vdash u:U}{E[\Gamma] \vdash (t\ u):T} 
    \\[1em]
    \frac{E[\Gamma; x : \Index] \vdash t : U}{E[\Gamma] \vdash (\mu x.t) : \forall x.U}
    \qquad
    \frac{E[\Gamma] \vdash t:\forall x.U \qquad E[\Gamma] \vdash u : \Index}{E[\Gamma] \vdash (t\ u):U\{x/u\}}
\end{gather*}

Finally, the big operator sum is modeled by folding a function over a set, with the typing rule as follows:
\[
    \frac{E[\Gamma] \vdash s : \SET(\sigma) \qquad E[\Gamma] \vdash f : \Basis(\sigma) \to \KType(\tau)}{E[\Gamma] \vdash \sum_{s} f : \KType(\tau)}.
\]

\begin{lemma}
    The typing of expressions is both decidable and unique.
\end{lemma}

\begin{proof}
    The type of an expression can be determined recursively. For any given function symbol and argument types, there is at most one typing rule, ensuring the uniqueness of typing.
\end{proof}






\subsection{Semantics}

The semantics of a language define the meaning of its expressions. In this context, the objective of our algorithm is to determine whether two expressions are semantically equivalent. We define the semantics in a denotational manner, mapping syntax to set-theoretic objects.

\subsubsection{Denotational Semantics}
The denotational semantics interpret every expression as an object in linear algebra, according to a valuation mapping \( v \), which assigns values to the variables in the expression. The semantics of an expression \( e \) with a given valuation \( v \) is denoted as \( \sem{e}_v \). Two expressions \( e_1 \) and \( e_2 \) are considered equivalent if their semantics are equal for all valuations, i.e., \( \sem{e_1}_v = \sem{e_2}_v \) for all \( v \).

The complete interpretation of terms and types is provided in~\Cref{sec: full denotational sem}. Variables typed with \( \Index \) are interpreted as finite sets, and the product of two indices \( \sem{\sigma_1 \times \sigma_2} \) is defined as the Cartesian product of the sets \( \sem{\sigma_1} \) and \( \sem{\sigma_2} \). More generally, each type is interpreted as a set. For example, the scalar type \( \sem{\SType} \) is interpreted as the set of complex numbers \( \mathbb{C} \), and the ket and bra types \( \sem{\KType(\sigma)} \) and \( \sem{\BType(\sigma)} \) are interpreted as the Hilbert space \( \mathcal{H}_{\sem{\sigma}} \) and its dual \( \mathcal{H}_{\sem{\sigma}}^* \), respectively. Terms are explained as the set elements. For example, the semantics of ket tensor product $\sem{K_1 \otimes K_2} \equiv \sem{K_1} \otimes \sem{K_2}$, is obtained by first calculating the semantics $\sem{K_1}$ and $\sem{K_2}$ as vectors, and then take the vector tensor product as result.

% One special case is the delta function \( \delta_{s,t} \), which is interpreted as:
% \[
%     \sem{\delta_{s,t}} =
%     \begin{cases}
%         1, & \text{if } \sem{s} = \sem{t}, \\
%         0, & \text{if } \sem{s} \neq \sem{t}.
%     \end{cases}
% \]d

The idea behind the interpretation of types and terms is to formalize the typing relation using set-theoretic inclusion. Specifically, for a well-formed context \( E[\Gamma] \), term \( t \), and type \( T \), if \( E[\Gamma] \vdash t : T \), then for any valuation \( v \), the semantics of \( t \) must lie within the semantics of \( T \).

\begin{lemma}
    For any well-formed context \( E[\Gamma] \), term \( t \), and type \( T \), if \( E[\Gamma] \vdash t : T \), then for all valuations \( v \), \( \sem{t}_v \in \sem{T}_v \).
\end{lemma}

\begin{proof}
    The proof follows directly by checking each case.
\end{proof}

This interpretation formalizes the standard understanding of Dirac notation and provides the foundation for the algorithm. However, computers cannot directly reason about equivalence through mathematical interpretations. Therefore, we proceed by defining a proof system that abstracts these concepts.



\subsubsection{Axiomatic semantics} 

The proof system for equivalence is based on equational logic, together with axioms that describe the properties of Dirac notation. A full list of these axioms can be found in~\Cref{sec: full axioms}. The axioms cover fundamental aspects of linear spaces, as well as other structures like the tensor and inner products. For example, we have the absorption law for zero symbols:
\(X \cdot \mathbf{0} = \mathbf{0},\)
and the bilinearity of the dot product:
\[
(a.X) \cdot Y = a \cdot (X \cdot Y), \quad X \cdot (Y_1 + Y_2) = X \cdot Y_1 + X \cdot Y_2, 
\]
\[
X \cdot (a.Y) = a \cdot (X \cdot Y), \quad (X_1 + X_2) \cdot Y = X_1 \cdot Y + X_2 \cdot Y.
\]

As mentioned in the introduction, a subset \( E \) of these axioms cannot be decided by term rewriting alone. The axioms in \( E \) include:
\[
\begin{aligned}
    \text{AC-equivalence} &\quad \text{e.g.,} \quad X + Y = Y + X, \quad (X + Y) + Z = X + (Y + Z), \\
    \alpha\text{-equivalence} &\quad \lambda x . A = \lambda y . A\{x/y\}, \\
    \text{SUM-SWAP} &\quad \sum_{i \in s_1} \sum_{j \in s_2} A = \sum_{j \in s_2} \sum_{i \in s_1} A, \\
    \text{scalar theories} &\quad \text{e.g.,} \quad a + 0 = a, \quad a \times (b + c) = a \times b + a \times c.
\end{aligned}
\]
The scalar theories are treated separately as a module and are not considered in this work. In the implementation, we use the Mathematica kernel to decide scalar equivalences.
These equational axioms provide an operable theory for the proof automation algorithm. Denotational semantics can be seen as one model for this theory, meaning that equivalences derived from the axioms always imply equivalence in the interpretations.
\begin{lemma}
    For all well-formed contexts \( E[\Gamma] \) and terms \( e_1, e_2 \), if \( \vdash e_1 = e_2 \), then \( \sem{e_1} = \sem{e_2} \).
\end{lemma}
\begin{proof}
    This follows directly from checking all cases.
\end{proof}

Thus, the axioms are sound with respect to denotational semantics. However, the reverse does not hold: there exist equivalences in denotational semantics that cannot be captured by these axioms. Nevertheless, our work focuses on solving practical examples, which are fully covered by the axioms in the experiments.

To conclude this section, we demonstrate the formalization of the symbols used in the motivating example.
\begin{example}[Formalizing the Motivating Example]
    \label{ex: formalizing motivating}
    Definitions and assumptions in the environment \( E \) are formalized as follows:
    \begin{align*}
        & \text{TPO} && := \mu T_1. \mu T_2. \lambda O : \OType(T_1, T_2). \sum_{i \in \mathbf{U}(T_1)} \sum_{j \in \mathbf{U}(T_2)} \bra{i} O \ket{j} . \ket{j}\bra{i} \\
        & &&\quad : \forall T_1. \forall T_2. \OType(T_1, T_2) \to \OType(T_2, T_1); \\
        &\text{phi} &&:= \mu T. \sum_{i \in \mathbf{U}(T)} \sum_{j \in \mathbf{U}(T)} \ket{(i, j)} : \forall T.\KType(T \times T); \\
        & T && : \Index; \\
        & M && : \OType(T, T).
    \end{align*}
    The symbol \( \text{TPO} \) represents the transpose of an operator, polymorphic on the Hilbert spaces \( T_1 \) and \( T_2 \). The symbol \( \text{phi} \) takes the index \( T \) and defines the maximally entangled states, summing over all basis elements in \( T \), as indicated by the universal set \( \mathbf{U}(T) \).
    With the assumption of the index \( T \) and operator \( M \), we can express the equivalence in the non-labelled version as:
    \[
    (\textrm{M} \otimes \mathbf{1}_\mathcal{O}(\textrm{T})) \cdot (\textrm{phi T}) = (\mathbf{1}_\mathcal{O}(\textrm{T}) \otimes (\textrm{TPO T T M})) \cdot (\textrm{phi T}).
    \]
\end{example}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Algorithm for Deciding Dirac Notation Equations}
\label{sec: decide}

We utilize the term rewriting technique to decide the equivalence of Dirac notation, based on its axiomatic semantics. The process involves normalizing two terms and checking whether they have identical syntax. This normalization is achieved through matching and substitution in universal algebra, using a set of predefined rewriting rules.

As mentioned in the semantics section, the axioms in \( E \) cannot be fully decided through term rewriting. DiracDec decides \( E \) by examining all possible permutations in the rewriting result. In this work, we introduce a more efficient approach by incorporating sorting algorithms into the normalization procedure. 

The normalization procedure consists of the following steps.
\begin{enumerate}
    \item \textbf{First Rewritings}: Expand definitions and simplify expressions.
    \item \textbf{Variable Expansion}: Consider scalar expressions to ensure completeness.
    \item \textbf{Second Rewritings}: Normalize terms modulo \( E \).
    \item \textbf{Sorting Without Bound Variables}: Normalize AC-equivalence.
    \item \textbf{Swap Successive Summations}: Normalize SUM-SWAP equivalences.
    \item \textbf{De Bruijn Normalization}: Normalize \( \alpha \)-equivalence.
\end{enumerate}

\subsection{Normalization Modulo \( E \) by Term Rewriting}

Term rewriting rules, represented as \( l \ \reduce\ r \), are applied recursively to normalize terms. In each step, subterms matching the left-hand side \( l \) of a rule are replaced with the corresponding right-hand side \( r \). The procedure terminates when no further rewritings can be made.
A comprehensive list of rewriting rules can be found in~\Cref{sec: rewriting rules}. Below are some key examples to illustrate the design:

One of our optimizations is using functions with indefinite arities. 
Therefore, we use a flattening rule to handle associativity with AC symbols:
\[
a_1 + \cdots + (b_1 + \cdots + b_m) + \cdots + a_n \ \reduce\ a_1 + \cdots + b_1 + \cdots + b_m + \cdots + a_n.
\]
Commutativity is handled later in the sorting step. Many of the rewriting rules are directly derived from the equational axioms, such as:
\begin{align*}
    & \textrm{(R-DOT6)} && \bra{s} \cdot \ket{t} \ \reduce\  \delta_{s, t}, \\
    & \textrm{(R-DELTA0)} && \delta_{s, s} \ \reduce\  1, \\
    & \textrm{(R-MULK1)} && O : \OType(\sigma, \tau) \Rightarrow O \cdot \mathbf{0}_{\KType(\tau)} \ \reduce\  \mathbf{0}_{\KType(\sigma)}, \\
    & \textrm{(R-MULK11)} && (O_1 \otimes O_2) \cdot (K_1 \otimes K_2) \ \reduce\  (O_1 \cdot K_1) \otimes (O_2 \cdot K_2).
\end{align*}
Some of these directions are obvious. For example, (R-DOT6) states that the inner product of two basis vectors is reduced to a delta expression, and (R-DELTA0) transforms a delta function on identical basis to a scalar \( 1 \). The rule (R-MULK1) reflects the axiom that multiplying a zero vector results in zero. This rule is conditional on typing, which is checked during rewriting. Some rules, like (R-MULK11), require a deeper understanding, such as the preference for tensor products over multiplication.

As a reference, the term rewriting system in DiracDec has been proven complete for all axioms, except for the sum symbol. The completeness result is derived from checking the confluence and termination of the system. Our rewriting rules are translations from DiracDec into the typed and abstract language, ensuring that the corresponding symbols in our system are also complete.

We also have additional rules that handle summations. For example:
\begin{align*}
    & \quad i \text{ free in } t \Rightarrow \sum_{i \in \mathbf{U}(\sigma)} \sum_{k_1 \in s_1} \cdots \sum_{k_n \in s_n} (\delta_{i, t}.A) \ \reduce\  \sum_{k_1 \in s_1} \cdots \sum_{k_n \in s_n} A\{i/t\}, \\
    & \quad \left( \sum_{i \in M} B \right) \cdot K \ \reduce\  \sum_{i \in M} (B \cdot K).
\end{align*}
The first rule eliminates delta expressions in summations, while the second rule pushes summations outside of inner products. While there is no guarantee of completeness for these rules, they work effectively in practice.

\subsubsection{Variable Expansion}
One important technique, revealed in the DiracDec work, is the expansion of variables, which is critical for proofs involving summation. For example:
\[
\frac{E[\Gamma] \vdash K : \KType(\sigma)}{E[\Gamma] \vdash K \ \reduce\ \sum_{i \in \mathbf{U}(\sigma)}(\bra{i} \cdot K).\ket{i}} \quad \quad
\frac{E[\Gamma] \vdash B : \BType(\sigma)}{E[\Gamma] \vdash B \ \reduce\ \sum_{i \in \mathbf{U}(\sigma)}(B \cdot \ket{i}).\bra{i}},
\]
\[
\frac{E[\Gamma] \vdash O : \OType(\sigma, \tau)}{E[\Gamma] \vdash O \ \reduce\ \sum_{i \in \mathbf{U}(\sigma)} \sum_{j \in \mathbf{U}(\tau)}(\bra{i} \cdot O \cdot \ket{j}).(\ket{i} \cdot \bra{j})}.
\]
These rules transform variables into their symbolic summations based on their decomposition over the basis. 
The rules are not terminating, therefore is applied recrusively once in the second step called \textit{variable expansion}.
Nevertheless, we have found that applying the expansion only once for all variables is sufficient for normalization.
\begin{lemma}
    Let \( \textrm{expand}(e) \) denote the result of expanding all variables in \( e \) once. For all well-typed terms \( e \) in \( E[\Gamma] \), \( \textrm{expand}(\textrm{expand}(e)) \) and \( \textrm{expand}(e) \) have the same normal form.
\end{lemma}
\begin{proof}
    Expanding a ket variable twice, for example, results in the following transformation:
    \[
    \sum_{i \in \mathbf{U}(\sigma)} (\bra{i} \cdot \sum_{j \in \mathbf{U}(\sigma)} (\bra{j} \cdot K) \cdot \ket{j}) \cdot \ket{i} \ \reduce\  \sum_{i \in \mathbf{U}(\sigma)} \sum_{j \in \mathbf{U}(\sigma)} (\bra{j} \cdot K \cdot \braket{i|j}) \cdot \ket{i},
    \]
    where the delta symbol elimination rule returns the term to its original form. The same holds for bra and operator terms.
\end{proof}



\subsection{Deciding Equational Theory \( E \)}

In the Mathematica implementation of DiracDec, the equational theory \( E \) is decided using unification, which attempts to find a substitution for the summation bound variables that makes two expressions syntactically equivalent. This unification process iterates through all permutations of AC symbol arguments, and its complexity is factorial in the maximum number of AC symbol arguments.

As the first improvement, we check \( \alpha \)-equivalence using the de Bruijn index~\cite{deBruijn1972lambda}, which replaces references to bound variable names with the distance from the lambda abstraction to the variable. For instance, the nominal lambda abstraction \( \lambda x. x \) is transformed into \( \lambda . 0 \), while \( \lambda x. \lambda y. (x\ (y\ x)) \) is transformed into \( \lambda.\lambda. (1\ (0\ 1)) \). This transformation into the de Bruijn index is performed as the final step in the normalization process to check equivalence between terms with different bound variable names.

The remaining axioms, such as AC-equivalence and SUM-SWAP, assert equivalence under permutations. A standard approach for deciding such equivalences is to normalize terms by sorting in a predefined order. For example, given the dictionary order \( a < b < c \), the term \( b + c + a \) (and any other AC-equivalent term) is normalized into \( a + b + c \). However, in our setting, two intertwined difficulties arise: how to assign an order to all terms in the language, and how to simultaneously sort for both axioms.

Consider the following two equivalent terms:
\[
\sum_{i \in s_1} \sum_{j \in s_2} \bra{i} A \ket{j} \times \bra{j} B \ket{i}
= 
\sum_{i \in s_2} \sum_{j \in s_1} \bra{i} B \ket{j} \times \bra{j} A \ket{i}
\]
While these two terms are equivalent, directly sorting the elements of scalar multiplication using lexical order does not yield the same form.

To address this issue, we propose an algorithm that sorts terms without considering bound variables. The key observation is that in a successive sum expression \( \sum_{i \in s_1} \cdots \sum_{j \in s_n} A \), the names and order of the bound variables \( i, \dots, j \) can be freely permuted. Therefore, all bound variables should be treated uniformly during sorting, and the order of summation can then be determined based on the position of the bound variables.

In the example above, we first ignore the bound variables and sort the sum body into \( \bra{\bullet} A \ket{\bullet} \times \bra{\bullet} B \ket{\bullet} \). Then, we swap the summations such that the bound variable at the first \( \bullet \) position appears at the outermost position. The results will have the same de Bruijn normal form, namely \( \sum_{s_1} \sum_{s_2} \bra{\$1} A \ket{\$0} \times \bra{\$0} B \ket{\$1} \).


To describe the algorithm in the following, we introduce two key notations. For a term \( e = f(a_1, a_2, \dots, a_n) \), \( \textrm{head}(e) \) denotes the function symbol \( f \), while \( \textrm{arg}(e, i) \) refers to the \( i \)-th argument \( a_i \) of the term. In this context, variables and constants are treated as functions with zero arguments.



\begin{definition}[Order Without Bound Variables]
Let \( \mathcal{B} \) represent the set of bound variables, with the assumption that all bound variables are unique. We also assume that a total order exists over all symbols. The relation \( e_1 =_\mathcal{B} e_2 \) holds if:
\begin{itemize}
    \item \( \textrm{head}(e_1) = \textrm{head}(e_2) \), and for all \( i \), \( \textrm{arg}(e_1, i) =_\mathcal{B} \textrm{arg}(e_2, i) \), or
    \item \( e_1 \in \mathcal{B} \) and \(e_2 \in \mathcal{B}\).
\end{itemize}

The relation \( e_1 <_\mathcal{B} e_2 \) holds between two terms if:
\begin{itemize}
    \item $e_1 \notin \mathcal{B}$ and $e_2 \in \mathcal{B}$, or
    \item $head(e_1) < head(e_2)$, or
    \item $head(e_1) = head(e_2)$, and there exists $n$ with $arg(e_1, n) <_\mathcal{B} arg(e_2, n)$, where $arg(e_1, i) =_\mathcal{B} arg(e_2, i)$ for all $i < n$.
\end{itemize}
\end{definition}
It can be shown that \( e_1 =_\mathcal{B} e_2 \) if and only if neither \( e_1 <_\mathcal{B} e_2 \) nor \( e_2 <_\mathcal{B} e_1 \) holds. The purpose of this ordering is to compare function symbols in a top-down manner while ignoring bound variables. The sorted order enables normalization of terms in terms of AC equivalence.
\begin{definition}[Sort Transformation]
    For a term $e$ with bound variable set $\mathcal{B}$,
    The sort transformation sort(e) is defined as
    \begin{itemize}
        \item $e$, if $e$ is a variable or constant;
        \item $\lambda x:T. \textrm{sort}(e')$, if $e \equiv \lambda x : T. e'$;
        \item $\mu x. \textrm{sort}(e')$, if $e \equiv \mu x. \textrm{sort}(e')$; or
        \item $f(\textrm{sort}(a_1), \cdots, \textrm{sort}(a_n))$, if $e \equiv f(a_1, \cdots, a_n)$. If $f$ is an AC symbol, then the order of sort($a_i$) is sorted ascendingly according to $<_\mathcal{B}$.
    \end{itemize}
\end{definition}

After sorting, the next step is the \textit{swap transformation}, which arranges successive summations based on the order of bound variables.
\begin{definition}[Swap Transformation]
For a term \( e \) with a sorting result \( \textrm{sort}(e) \), the swap transformation proceeds by ordering all bound variables according to their first appearances, except in function definitions \( \lambda x \) and \( \mu x \). The swap transformation then reorders the successive summations accordingly.
\end{definition}

The algorithm that applies the sort and swap transformations, followed by de Bruijn normalization, successfully handles all equivalences in our benchmark. We formalize the completeness of this transformation in the following conjecture:

\begin{conjecture}[Completeness of Transformation]
    For any two terms \( e_1 \) and \( e_2 \) that are equivalent under AC equivalence, SUM-SWAP, and \( \alpha \)-equivalence, they will have the same form after sort, swap, and de Bruijn transformations.
\end{conjecture}



% The order depends on there occurances in the last sorting result. If no occurance, then the order will depend on the set (for sum) and the type (for lambda abstraction only).

%%%%%%%%%%%%%%%%%%%%%%%


% The idea is to assign an order to terms, which is independent on the bound variables. Because we can have terms with nested AC symbols.

Lastly, we can prove that the equivalence established by this normalization procedure is sound with respect to the semantics.

\begin{theorem}[Soundness]
    For any well-formed context \( E[\Gamma] \) and well-typed expressions \( e_1 \) and \( e_2 \), if  $e_1$ and $e_2$ have the same normal form, then \( \sem{e_1} = \sem{e_2} \).
\end{theorem}

\begin{proof}
    The soundness of the term rewriting procedure follows from the fact that each rewriting rule preserves equivalence. Furthermore, the operations in the sort and swap transformations respect the AC-equivalence and SUM-SWAP axioms. Finally, the de Bruijn normalization ensures soundness for \( \alpha \)-equivalence.
\end{proof}



% Labelled Dirac Notation

\input{labelled}


\section{Implementation and Case Study}

The main purpose of this work is to build a practical tool that works well in checking Dirac notation equations. The refinements and extensions above concludes in our implementation called Dirace, a solver written in \CC. It has a parser built by ANTLR4, and scalar reasonings are powered by a Mathematica kernel. The user can use commands to make definitions and assumptions in the maintained context, conduct the normalization and equivalence checking, and obtain the rewriting trace output. This implementation 
is tested on the benchmark of the DiracDec work, and succeeds in proving most of them efficiently. 
It can be used from the command line interactively, or can be integrated into other \CC\ projects as a library.

\subsubsection{Project Structure}
The project structure is illustrated in~\Cref{fig: dirace structure}.
\texttt{ualg} is the module for universal algebra, defining basic concepts like terms and substitutions. It serves as the library for \texttt{dirace}, which are then utilized in the example benchmarks and the toplevel command line application. The components of \texttt{dirace} are as follows:
\begin{itemize}
    \item \texttt{symbols.cpp}: the reserved symbols and AC symbols;
    \item \texttt{syntax\_theory.cpp}: syntax related algorithms, such as de Bruijn normalization and freeness of variables;
    \item \texttt{calculus.cpp}: type checker and intergration with Mathematica;
    \item \texttt{reduction.cpp}: all the rewriting rules and transformations;
    \item \texttt{dirac\_parser.cpp}: parser for Dirac notation and Dirace commands;
    \item \texttt{prover.cpp}: the prover that maintains the context and process commands like definition or equivalence checking.
\end{itemize}

\input{dirace.tex}

The internal data structure for terms is a pointer-based syntax tree following the function application style:
\[
    \texttt{
        term ::= ID | ID [term (, term)*].
    }
\]
The syntax tree can be an identifier, or an application with an identifier as the function head, and several syntax trees as arguments. There are several Dirac notation terms and their corresponding syntax trees.
\footnotesize{
\begin{align*}
    & X_1 + X_2 + X_3 && \texttt{ADD[X1, X2, X3]} 
    \\
    & \lambda x: \OType(T_1,  T_2). x^\dagger && \texttt{FUN[x, OTYPE[T1, T2], ADJ[x]]}
    \\
    & \sum_{i \in \mathbf{U}(T)} \ket{i} \bra{i} && \texttt{SUM[USET[T], FUN[i, BASIS[T], OUTER[KET[i], BRA[i]]]]}
\end{align*}
}
The syntax tree structure is also compatible with the datatype of Mathematica. This improves the interoperability between Dirace and the Mathematica system, enabling them to work interleavingly.
To improve usability, Dirace also supports many special syntacies for terms,  and most Dirac notation terms will be encoded in the natural way.
Here are some examples for the parsing syntax.

\begin{figure}
    \center
\begin{tabular}{c >{\centering\arraybackslash}p{4cm} l}
    \hline
    syntax & parsing result & explanation \\
    \hline
    \texttt{|e>} & \texttt{KET[e]} & the ket basis\\
    \texttt{e1 + ... + en} & \texttt{ADD[e1, ..., en]} & the addition\\
    \texttt{e1\ e2} & \texttt{COMPO[e1, e2]} & composition in Dirac notation \\
    \texttt{e1\^{}*} & \texttt{CONJ[e1]} & scalar conjugation \\
    \texttt{fun i : T => X} & \texttt{FUN[i, T, X]} & lambda abstraction \\
    \hline
\end{tabular}
\end{figure}

Finally, Dirace uses a prover to host the computation. The prover maintains a well-formed context $E[\Gamma]$, and processes commands to modify the context and conduct calculations. The commands are listed below.
\begin{itemize}
    \item \texttt{\textcolor{NavyBlue}{Def} ID := term.} It defines the \texttt{ID} as the \texttt{term}, using the \textbf{W-Def} typing rule.
    \item \texttt{\textcolor{NavyBlue}{Var} ID := term.} It make an assumption of \texttt{ID} with the \texttt{term} as type, using the \textbf{W-AssumeE} typing rules.
    \item \texttt{\textcolor{NavyBlue}{Check} term.} Type checking the \texttt{term} and output the result.
    \item \texttt{\textcolor{NavyBlue}{Normalize} term.} Normalize the \texttt{term} using the algorithm introduced in~\Cref{sec: decide}.
    \item \texttt{\textcolor{NavyBlue}{CheckEq} term \textcolor{NavyBlue}{with} term.} Check the equivalence of the two terms calculating and comparing their normal forms.
\end{itemize}
The prover will type check the terms for each command. We can also use \texttt{\textcolor{NavyBlue}{Normalize} term \textcolor{NavyBlue}{with trace}.} to output the proof trace during normalization. The proof trace is a sequence of records, including the rule or transformation appied, the position of application, and the pre- and post-transformation terms. The record helps understand the normalization procedure better, and can be turned into verified proofs in theorem provers in the future.

\subsubsection{Use Case}
Here we encode the motivating~\Cref{ex: motivating}, examine and explain how it is checked in Dirace. The encoding is shown below.

    \begin{lstlisting}[style=dirace]
Var T : INDEX. Var M : OTYPE[T, T].
Def phi := idx T => Sum nv in USET[T], |(nv, nv)>.
Var r1 : REG[T]. Var r2 : REG[T].
CheckEq M_r1;r1 (phi T)_(r1, r2) with (TPO T T M)_r2;r2 (phi T)_(r1, r2).
    \end{lstlisting}        

The first three lines use the \texttt{\textcolor{NavyBlue}{Var}} and \texttt{\textcolor{NavyBlue}{Def}} commands to set up the context for the Dirac notation.
\texttt{T} is a type index, representing arbitrary Hilbert space types. \texttt{M} is assume to be an operator in the Hilbert space with type \texttt{T}. \texttt{phi} is defined as the maximally entangled state, depending on the bound variable \texttt{T} as index.
\texttt{r1} and \texttt{r2} are register names for the two subsystems.

In the left hand side of \texttt{\textcolor{NavyBlue}{CheckEq}} command, \texttt{M\_r1;r1} denotes the labelled notation $M_{r_1; r_1}$, and \texttt{(phi T)\_(r1, r2)} denotes the entangled state $\ket{\Phi}_{(r_1, r_2)}$. They are connected by a white space, which is parsed into the composition of Dirac notation, and will be reduced into the operator-ket multiplication after typing. The right hand side is interpreted similarly, except the defined symbol \texttt{TPO} in the environment:

\begin{lstlisting}[style=dirace]
Def TPO := idx sigma => idx tau => fun O : OTYPE[sigma, tau] => Sum i in USET[sigma], Sum j in USET[tau], (<i| O |j>).(|j> <i|).
\end{lstlisting}

The \texttt{TPO} symbol represents the transpose of operators, and encodes the formalization in~\Cref{ex: formalizing motivating}. Thanks to the design of environment and functions, many other commonly used symbols in Dirac notation are encoded and provided as defined symbols in Dirace.

Within one second, the prover reports the result of equivalence with their common normal form:
    \begin{lstlisting}[style=dirace]
The two terms are equal.
[Normalized Term] SUM[USET[T], FUN[BASIS[T], SUM[USET[T], FUN[BASIS[T], SCR[DOT[BRA[$\texttt{\$1}$], MULK[M, KET[$\texttt{\$0}$]]], LTSR[LKET[$\texttt{\$1}$, r1], LKET[$\texttt{\$0}$, r2]]]]]]] : DTYPE[RSET[r1, r2], RSET]
    \end{lstlisting}

The normal form is in the internal syntax tree format mentioned above. A more readable interpretation is:
\[
\sum_{\mathbf{U}(T)} \sum_{\mathbf{U}(T)} \bra{\$1}M\ket{\$ 0} . \ket{\$1}_{r_1} \otimes \ket{\$0}_{r_2} : \DType(\{r_1, r_2\}, \emptyset).
\]
Here $\$0$ and $\$1$ are de Bruijn indices. The result is a ket on the $\{r_1, r_2\}$ system as expected, and follows pattern proposed in~\Cref{sec: labelled}.




\subsubsection{Benchmark performance}

To evaluate Dirace, we first test the examples from DiracDec benchmark and make a comparison.
The experiments are carried out using a MacBook Pro with M3 Max chip.

\begin{figure}
    \center
    \begin{tabular}{c|c c c|c c c}
        \hline
        \multirow{2}{*}{source} & \multicolumn{3}{c|}{DiracDec} & \multicolumn{3}{c}{Dirace} \\
        \cline{2-7}
                                 & expressable & success & time(s)           & expressable & success & time(s)                 \\
        \hline
        textbook(QCQI)          & 18          & 18        &    1.02        &    18      & 18          &   0.82      \\
        CoqQ                    & 162          & 156       &    48.69       &   158     &  158   &     9.74     \\
        circuits                 & 2          & 2       &    17.67       &   3     &  2   &     1.4     \\
        research paper                & 4          & 4         &  59.53       &   4    & 4       &  0.73     \\
        \hline
    \end{tabular}        
    \caption{For DiracDec, examples that cannot be decided within 60 seconds are not included.}
\end{figure}

The timing of Dirace does not include the initialization of Mathematica kernel link, which takes about 3 seconds in the beginning.
As to expressibility, the language for DiracDec has the support for projectors $\texttt{fst}$ and $\texttt{snd}$ on basis pairs, satisfying $\texttt{fst} (s, t) = s$ and $\texttt{snd} (s, t) = t$. We found this feature is almost not used, so we removed the support. As a result, Dirace encodes 158 examples for the CoqQ part, 4 less than DiracDec. For decidability, we improved the rewriting rules about sum for Dirace, and proved several more examples failed by DiracDec. 
The main difference is about their time efficiency. Because of our algorithm to decide AC-equivalence and SUM-SWAP, Dirace has a significant efficiency improvement, especially on those ``computational examples'' mentioned in the DiracDec paper.
One typical example comes from the paper by Jens about the equivalence of operators for qubits. The system has to decompose the term on the concrete $\ket{0}$ and $\ket{1}$ basis, resulting a lot of addition elements. It takes DiracDec about one minute, but Dirace solves it within one second.



We also built an example benchmark for labelled Dirac notation, see~\Cref{sec: examples for labelled}.


\section{Related Work}

Automated theorem proving has seen significant advancements in recent years, particularly through the development of satisfiability modulo theories (SMT) solvers,
% SMT solvers extend propositional satisfiability by integrating theories such as arithmetic, arrays, and bit-vectors, making them suitable for solving a wide range of verification problems in both hardware and software domains. 
including prominent tools like Z3. These solvers have become essential in various fields such as formal verification, synthesis, and model checking. 
Equational reasoning is another crucial area of research within automated theorem proving, which focuses on solving problems that involve equations between terms in an algebraic structure. 
Equational provers, such as Vampire and E, have played a pivotal role in addressing the challenge of proving equations in first-order logic, employing sophisticated algorithms like superposition and term rewriting.

Formal verification of quantum computation is receiving increasing attentions during these years. See~\cite{Lewis2023} for a comprehensive review. 
Verification frameworks in Coq include the foundational formalization CoqQ and quantum circuit language QWIRE. 
Verifications of quantum programs are also considered, such as the Hoare logic based methods [] and model checking based methods [].
The equational reasoning of Dirac notation is crucial for establishing property proofs in these works.
Verification theoreis and tools based on other languages are also proposed, such as PyZX for reasoning and simplification of ZX-calculus.




\section{Conclusion and Future Work}
Based on the first equational reasoning tool for Dirac notation called DiracDec, this work improves and extends the theory for practical applications, and provides the solver Dirace. Experiments show that the tool demonstrates advantages in decidability, efficiency and usability. 

We expect Dirace to have applications in areas like quantum program verification or proofs of post-quantum cryptography protocols in the future.
One promising following up is to connect Dirace with theorem provers like Coq. It involves transforming theorem prover expressions into Dirace, and verify the proof trace of Dirace in theorem provers. Besids, most quantum program verifiers nowadays depend on matrix calculations. Dirace can serve as the replacement for matrix methods to enable symbolic deductions.


%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{credits}
%     \subsubsection{\ackname} A bold run-in heading in small font size at the end of the paper is
%     used for general acknowledgments, for example: This study was funded
%     by X (grant number Y).
% \end{credits}
    
    


%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{ref}
%

\appendix
\include{appendix}

\end{document}