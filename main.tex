% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}


% \usepackage[utf8]{inputenc}
% \usepackage[margin=0.8in]{geometry}




\usepackage{color}
\usepackage{amsmath}
%\usepackage{amssymb}
\usepackage{graphicx}
% \usepackage{amsthm}
\usepackage{stmaryrd}
\usepackage[all]{xy}
\usepackage{multirow}
\usepackage{paralist}
\usepackage{hhline}
\usepackage{bm}
\usepackage{longtable}
\usepackage{makecell}
\usepackage{mdframed}

\usepackage{wasysym}
\usepackage{extarrows}
\usepackage{tikz}

% add new commands for comments here
\newcommand{\yx}[1]{\textit{\color{blue}[YX] : #1}}
\newcommand{\lz}[1]{\textit{\color{red}[LZ] : #1}}

\newcommand{\modify}[1]{{\color{red}#1}}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{stmaryrd}
\usepackage{hyperref}

\usepackage{braket}
\usepackage{cleveref}

\input{lstlisting}

\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}
\usetikzlibrary{trees}
\tikzstyle{arrow} = [thick,->,>=stealth]



\newenvironment{ruletable}[1]
{
    \begin{longtable}{cl}
    \caption{#1}\\
    \hline
    \textbf{Rule} & \textbf{Description} \\
    \hline
    \endfirsthead

    \hline
    \textbf{Rule} & \textbf{Description} \\
    \hline
    \endhead

    % \hline
    % \multicolumn{2}{r}{\textit{Continued on the next page}} \\
    \hline
    \endfoot

    \hline
    \endlastfoot
}
{
    \end{longtable}
}

% define C++ logo
\newcommand{\CC}{C\nolinebreak\hspace{-.05em}\raisebox{.4ex}{\tiny\bf +}\nolinebreak\hspace{-.10em}\raisebox{.4ex}{\tiny\bf +}}
\def\CC{{C\nolinebreak[4]\hspace{-.05em}\raisebox{.4ex}{\tiny\bf ++}}}


%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
\usepackage{color}
\renewcommand\UrlFont{\color{blue}\rmfamily}
\urlstyle{rm}
%
\begin{document}
%
\title{Dirace: Practical Proof Automation of Dirac Notation Equations}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %
% %\titlerunning{Abbreviated paper title}
% % If the paper title is too long for the running head, you can set
% % an abbreviated paper title here
% %
% \author{First Author\inst{1}\orcidID{0000-1111-2222-3333} \and
% Second Author\inst{2,3}\orcidID{1111-2222-3333-4444} \and
% Third Author\inst{3}\orcidID{2222--3333-4444-5555}}
% %
% \authorrunning{F. Author et al.}
% % First names are abbreviated in the running head.
% % If there are more than two authors, 'et al.' is used.
% %
% \institute{Princeton University, Princeton NJ 08544, USA \and
% Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany
% \email{lncs@springer.com}\\
% \url{http://www.springer.com/gp/computer-science/lncs} \and
% ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
% \email{\{abc,lncs\}@uni-heidelberg.de}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}

    Dirac notation is the fundamental language in quantum computation and quantum information. Recently, the term rewriting system DiracDec~\cite{diracdec} was introduced to automate the equational reasoning with Dirac notation, a critical yet time-intensive task. This work bases upon and extends DiracDec, aiming to develop a solver optimized for practical applications. Enhancements include an improved typing system, a simplified language and rewriting system, more efficient algorithms, and added support for labelled Dirac notation. Our solver Dirace is implemented in \CC\ with a Mathematica backend, and demonstrates advantages in decision-making power and time efficiency.


% \keywords{First keyword  \and Second keyword \and Another keyword.}
\end{abstract}
%
%
%



%%%%%%%%%%%%%%%%
\newcommand*{\sem}[1]{{\llbracket #1 \rrbracket}}
\newcommand{\DiracDec}{\textsf{DiracDec}}

\newcommand{\reduce}{\triangleright}

\newcommand{\Sort}{\mathsf{Sort}}
\newcommand{\WF}{\mathcal{WF}}

\newcommand{\Index}{\mathsf{Index}}
\newcommand{\Type}{\mathsf{Type}}
\newcommand{\Basis}{\mathsf{Basis}}

\newcommand{\SType}{\mathcal{S}}
\newcommand{\KType}{\mathcal{K}}
\newcommand{\BType}{\mathcal{B}}
\newcommand{\OType}{\mathcal{O}}
\newcommand{\SET}{\mathsf{Set}}

\newcommand{\ZEROK}{\mathbf{0}_\mathcal{K}}
\newcommand{\ZEROB}{\mathbf{0}_\mathcal{B}}
\newcommand{\ZEROO}{\mathbf{0}_\mathcal{O}}

\newcommand{\PAIR}{\mathsf{PAIR}}

\newcommand{\ZERO}{\mathsf{0}}
\newcommand{\ONE}{\mathsf{1}}
\newcommand{\ADDS}{\mathsf{ADDS}}
\newcommand{\ADD}{\mathsf{ADD}}
\newcommand{\MULS}{\mathsf{MULS}}
\newcommand{\MUL}{\mathsf{MUL}}
\newcommand{\CONJ}{\mathsf{CONJ}}
\newcommand{\CJG}{\mathsf{CJG}}
\newcommand{\ADJ}{\mathsf{ADJ}}
\newcommand{\DELTA}{\mathsf{DELTA}}
\newcommand{\DOT}{\mathsf{DOT}}
\newcommand{\SCR}{\mathsf{SCR}}
\newcommand{\TSR}{\mathsf{TSR}}
\newcommand{\KET}{\mathsf{KET}}
\newcommand{\BRA}{\mathsf{BRA}}
\newcommand{\ONEO}{\mathbf{1}_\mathcal{O}}
\newcommand{\OUTER}{\mathsf{OUTER}}
\newcommand{\MULK}{\mathsf{MULK}}
\newcommand{\MULB}{\mathsf{MULB}}
\newcommand{\MULO}{\mathsf{MULO}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

In 1939, Dirac proposed his notation~\cite{dirac1939new} for quantum mechanics, which is designed to represent linear algebra formulae in a compact and convenient way.
For instance, $a\ket{\psi} + b\ket{\phi}$ indicates the addition of two vectors, i.e., the superposition of two states $\ket{\psi}$ and $\ket{\phi}$.
Dirac notation is now widely accepted as the working language in quantum computation and quantum information. The reasonings of Dirac notation play a fundamental role in research and application, just like boolean and integer logic to classical computer science. 
For example, formalization works of quantum algorithms and quantum programming languages involves plenty of equational proofs of Dirac notation, which are critical, repeating but time-intensive jobs.
Dirac notation are also used in quantum programming languages to define the program states, operations and assertions. In order to automate the verification procedure, we need to simplify and check the equivalence of pre-conditions. 
However, unlike the existence of SAT and SMT solver, we are still in need of a working Dirac notation solver, and this absence has become an obstacle of many areas.

Recently, Xu et al.~\cite{diracdec} proposed a theory to decide the equivalence of Dirac notation, as well as a prototype implementation in Mathematica called DiracDec.
They proved that the equivalence of basic Dirac notation are decidable.
Their algorithm sticks with a pure term rewriting system, and is proved to be confluent and terminating.
Even though, there is still a gap between DiracDec and a practical solver for Dirac notation equivalence.

One problem is the algorithm efficiency for equivalence out of the scope of rewritings. DiracDec decides the whole equational theory by rewriting modulo $E$, where $E$ is a set of equational axioms that cannot be decided by normalization in rewritings, e.g. the associativity and commutativity (AC) of some function symbols. DiracDec uses a direct by inefficient algorithm to decide $E$, which search through all possible permutations and has factorial complexity.
This is witnessed in their evaluation: DiracDec is not good at dealing with ``computational examples'', which has many AC symbols and are therefore time consuming.

Usability is another problem.
DiracDec does not support labelled Dirac notation, which use registers to denote the subsystem, and express the state locally.
The typing of DiracDec only deals with Dirac notation, which is not sufficient for a working scenario, where we want to have defined symbols and a context for the typing assumptions of variables.
Moreover, to avoid type checking during term rewriting, DiracDec separate the same symbol (e.g. multiplication) for different types to disambiguate, which makes the system bloated.
Also, it is hard to integrate the Mathematica implementation as a solvers into other projects.

The system design involves a trade-off between simplicity and efficiency. The simplicity of term rewriting in DiracDec allows them to reach satisfying theoretical results, but it is also a constraint for optimization.
Based on DiracDec, this work aims at building a practical solver. It transforms the term rewriting system into a hybrid algorithm, and overcomes the problems mentioned above. Our main technical contributions are:
\begin{itemize}
    \item An efficient algorithm to decide the equational theories in $E$. The core idea is to perform equivalence checking through normalization, with the normal form for $E$ being obtained by sorting.
    \item The support for constant register labels. The equivalence decision of labelled Dirac notation is reduced to the unlabelled situation.
    \item A more usable \CC\ solver Dirace with abstract language and typing. We also support to define symbols (e.g., transpose and trace) using the functions syntax.
\end{itemize}

As an evaluation, we tested Dirace on the benchmark of DiracDec and new examples for labelled Dirac notation. 
The result shows significant improvement in decidability and efficiency over DiracDec.
% Dirace successfully decides all the examples that are expressable in its language, including those failed by DiracDec because of complexity or insufficient decision power.

% \yx{mention the dilemma of simplicity and efficiency}





\section{Motivation and Preliminary}
One interesting fact about the quantum world is that for two maximally entangled states, applying one operator $M$ on one subsystem is equivalent to applying $M^T$, the transpose of $M$, on the other. This property holds no matter how far the two systems are separated, and is expressed as an equation of Dirac notation.
\begin{example}
    \label{ex: motivating}
    Let $q$ and $r$ be two quantum systems on $\mathcal{H}_T$ space. Let $M$ be a quantum operation on $\mathcal{H}_T$,
    and $\ket{\Phi} = \sum_{i \in T} \ket{i}\otimes \ket{i}$ be the maximally entangled state, then we have
    \[
    M_q \ket{\Phi}_{q; r} = M_r^T \ket{\Phi}_{q; r}.
    \]
\end{example}
Here $q$ and $r$ are called labels, denoting the system for Dirac notation.
To automate reasoning about such equations, we need to formalize the language and develop a proof system.
% The following paragraphs briefly introduce the Dirac notation and the universal algebra framework we use.

\subsubsection{Dirac notation}
Quantum states live in complex Hilbert spaces. We use vectors in the space to descirbe pure quantum states, and operations are described by linear transformations. 
It uses the ket $\ket{i}$ and the bra $\bra{i}$ to indicate bases of the space and the dual space. Together with other variable symbols, they are composed with each other in sequence, and the composition will be interpreted into different operations, depending on the type of operands. For example, $\braket{i|j}$ represents the inner product of $\bra{i}$ and $\ket{j}$, which is a scalar, while $\ket{i}\bra{j}$ represents the outer product, resulting in an operator. 
Dirac notation also use $\otimes$ to indicate the vectors and operators in the tensor product space.

Dirac notation further enjoys the property that the interpretation is independent on the order of composition, thus parentheses can be omitted. For example, the formula \(\bra{i}\ket{\phi}\bra{\psi}\ket{j}\) can be understood as
\[
    \braket{i|\phi}\braket{\psi|j} = \bra{i} (\ket{\phi}\bra{\psi}) \ket{j},
\]
and they are equivalent for all variables.

% With the concrete basis, Dirac notation can be interpreted as matrices. For example, the ket of two basis of qubit states are column vectors $\ket{0} = \begin{bmatrix} 1 \\ 0 \end{bmatrix}$ and $\ket{1} = \begin{bmatrix} 0 \\ 1 \end{bmatrix}$, and the corresponding bras are row vectors in the dual space $\bra{0} = \begin{bmatrix} 1 & 0 \end{bmatrix}$ and $\bra{1} = \begin{bmatrix} 0 & 1 \end{bmatrix}$.
% The calculation between Dirac notation then corresponds to matrix operatoins. For example, inner product $\braket{0| 1} = \begin{bmatrix} 0 & 1 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} = 0$, and tensor product $\ket{0} \otimes \ket{1} = \ket{(0, 1)} = \begin{bmatrix} 1 \\ 0 \end{bmatrix} \otimes \begin{bmatrix} 0 \\ 1 \end{bmatrix} = \begin{bmatrix} 0 \\ 1 \\ 0 \\ 0 \end{bmatrix}$.

In practice, Dirac notation are combined with other syntax, such as the big operator sum $\sum_{i \in S} A$, for better expressiveness. We also use labelled Dirac notation like $\ket{i}_q \otimes \ket{i}_r$ to denote the quantum system in consideration, where Dirac notation are subscripted with registers.


\subsubsection{Universal algebra}
We use universal algebra and equational logic to formally represent Dirac notation and the reasoning procedure.
A universal algebra defines a signature of function symbols.
Terms in the algebra are constructed by constants, variables or function application on terms. 
Other basic concepts like substitution of variables or pattern matching are also defined.
In our case of Dirac notation, the signature consists of constructors and operations like $\ket{i}$ or $A \otimes B$.
Reasonings of Dirac notation terms follow the equational logic. It defines an equaitonal relation compatible with substitution and term construction, which essentially formalizes the common sense of equivalence in algebra.



\section{Language, Typing and Semantics}
The first step is to formally pin down the language for Dirac notation.
As a reference, the language in DiracDec has a concrete design, meaning that the same syntax for different types corresponds to different symbols.
Our intention is to move from the concrete design to a more abstract one. This is closer to the casual Dirac notation we use, and simplifies the term rewriting system.

For this purpose, our language involves three layers: the index, the type and the term.
Terms describe the concrete instances like ket, bra and operator, which will be checked and typed.
Index represents classical datatypes, and they appear in type expressions to distinguish between different Hilbert spaces and sets.
\begin{definition}[index syntax]
    The syntax for type indices is
    \begin{align*}
        \sigma ::=\ & x \mid \sigma_1 \times \sigma_2.
    \end{align*}
\end{definition}
Here $x$ is a variable. $\sigma_1 \times \sigma_2$ is the product type for tensor product space or Cartesian product sets.

\begin{definition}[type syntax]
    The syntax for Dirac notation types is
    \begin{align*}
        T ::=\ & \Basis(\sigma) \mid \SType \mid \KType(\sigma) \mid \BType(\sigma) \mid \OType(\sigma_1, \sigma_2) \mid T_1 \to T_2 \mid \forall x.T \mid \SET(\sigma). \\
    \end{align*}
\end{definition}
$\Basis(\sigma)$ is the type for basis in index $\sigma$. $\SType$ indicates scalars, $\KType(\sigma)$ and $\BType(\sigma)$ indicates ket and bra terms in Hilbert space $\sigma$, and $\OType(\sigma_1, \sigma_2)$ indicates linear operators with Hilbert space $\sigma_2$ as domain and $\sigma_1$ as codomain.
$\mathsf{Set}(\sigma)$ is the type of subsets in $\sigma$ index, and is used to denote the values of bound variables in summation.
The remaining two generators are types for functions. $T_1 \to T_2$ denotes normal functions, which accepts a $T_1$ type argument and results in a $T_2$ type term. $\forall x. T$ denotes index functions, which accepts an index argument $x$ and results in a $T$ type term, where $T$ can depend on $x$.
Index functions are necessary for defining transformations that are polymorphic on Hilbert spaces.

\begin{definition}[term syntax]
    The syntax for Dirac notation terms is
    \begin{align*}
        e ::=\ & x \mid \lambda x : T.e \mid \mu x.e \mid e_1\ e_2 \mid (e_1, e_2) \\
        & |\ 0 \mid 1 \mid \ADDS(e_1, \cdots, e_n)  \mid e_1 \times \cdots \times e_n \mid e^*  \mid \delta_{e_1, e_2} \mid \DOT(e_1, e_2) \\
        & |\ \ZEROK(\sigma) \mid \ZEROB(\sigma) \mid \ZEROO(\sigma_1, \sigma_2) \mid \ONEO(\sigma) \\
        & |\ \ket{e} \mid \bra{t} \mid e^\dagger \mid e_1.e_2 \mid \ADD(e_1, \cdots, e_n) \mid e_1 \otimes e_2 \\
        & |\ \MULK(e_1, e_2) \mid \MULB(e_1, e_2) \mid \OUTER(e_1, e_2) \mid \MULO(e_1, e_2) \\
        & |\ \mathbf{U}(e) \mid e_1 \star e_2 \mid \sum_{e_1} e_2.
    \end{align*}
\end{definition}
The generators are explained in order.
$\lambda x : T.e$ is the abstraction for normal functions, and $\mu x.e$ is the abstraction for index functions.
$e_1\ e_2$ is function application. 
% $e_1 \circ e_2$ is the composition operator of Dirac notation.
% $\hat{0}$ and $\hat{1}$ are constant basis of $\Basis(\mathsf{bool})$ type.
$(e_1, e_2)$ is the basis pair for product types. $0$, $1$, $\ADDS$, $e_1 \times \cdots \times e_n$ and $e^*$ are symbols for scalars. 
The next line includes constant symbols for ket, bra and operator.
$e^\dagger$ denotes the conjugate transpose of $e$. $e_1.e_2$ denotes scaling the term $e_2$ with scalar $e_1$.
$\mathbf{U}(e)$ is the universal set with index $e$. $e_1 \star e_2$ is the Cartesian product. $\sum_{e_1} e_2$ is the big operator sum, which is modelled by folding the function $e_2$ over value sets $e_1$. Usually, the sum body is specified by an abstraction. Therefore we use the notation $\sum_{x \in s} X$ to denote $\sum_{s} \lambda x : T . X$ as well.
Here $\ADDS$ and $\ADD$ are two different AC symbols representing the scalar addition and the linear algebra addition respectively. 
% They will be denoted as $a_1 + \cdots + a_n$ and $X_1 + \cdots + X_n$.
There are five kinds of linear algebra multiplications among ket, bra and operator. We encode the typing information by using five different symbols, namely $\DOT$, $\MULK$, $\MULB$, $\OUTER$ and $\MULO$. 

Compared to DiracDec, the addition, adjoint, scaling and tensor product symbols are merged together.
They are denoted as $B\cdot K$, $K_1 \cdot K_2$, $B_1 \cdot B_2$, $K \cdot B$ and $O_1 \cdot O_2$, respectively.
The multiplications are still separated because their properties do not have to much overlap.


\subsection{Typing System}

Typing is the procedure to classify the term through a proof system in a typing context. 
Our context consists of the environment $E$ for definitions and assumptions, and the context $\Gamma$ for bound variables. 
$E$ and $\Gamma$ are sequences of assumptions $x : T$ or definitions $x := t : T$.
\begin{definition}[environment and context]
    \begin{align*}
        E ::=\ & [] \mid E; x : \Index \mid E; x : T \mid E; x := t : T. \\
        \Gamma ::=\ & [] \mid \Gamma; x : \Index \mid \Gamma; x : T.
    \end{align*}
\end{definition}
Definitions refer to the symbols that can be unfolded. Definition symbols usually have abstract meanings, and here we use them to encode more operations in Dirac notation, such as transpose and trace.
Assumptions are the declarations of the type for variables. In the scenario of equational proofs, variable assumptions are universally quantified implicitly.

The type checking of our language involves maintaining a well-formed environment and context $E[\Gamma]$.
We say an expression $t$ has type $X$ in context $E[\Gamma]$, if the typing judgement $E[\Gamma] \vdash t : X$ can be proved through the typing rules in~\Cref{sec: full typing rules}. Here we present and explain the rules selectively. Firstly, well-formed contexts $\WF(E)[\Gamma]$ are built in the incremental way, e.g.:
\[
    \frac{}{\WF([])[]}
    \qquad
    \frac{\WF(E)[] \qquad x \notin E}{\WF(E; x : \Index)[]}
    \qquad
    \frac{E[]\vdash t:T \qquad x \notin E}{\WF(E; x:=t:T)[]}.
\]
Starting from an empty context, we can assume new index symbols, and assume or define symbols with checked types. Based on the well-formed context, typing judgements can be proved by information from $E[\Gamma]$, or built inductively. In the following rules, for example, the condition $x : \Index \in E[\Gamma]$ is true if $E$ or $\Gamma$ has the assumption in their sequences. $\KType(\sigma)$ will be a valid type for kets, if the argument $\sigma$ is typed as the index.
\begin{gather*}
    \frac{\WF(E)[\Gamma] \qquad x : \Index \in E[\Gamma]}{E[\Gamma] \vdash x : \Index}
    \qquad
    \frac{E[\Gamma] \vdash \sigma : \Index}{E[\Gamma] \vdash \KType(\sigma) : \Type}
\end{gather*}

The Dirac notation will then be typed accordingly. For example, the ket syntax $\ket{t}$ has type $\KType(\sigma)$, if $t$ is typed as a basis term of index $\sigma$. Also, the inner product of a bra and a ket with the same type index $\sigma$ is typed as the scalar. This corresponds to the constraint of inner products that vectors should be in the same Hilbert space.
\begin{gather*}
    \frac{E[\Gamma]\vdash t : \Basis(\sigma)}{E[\Gamma] \vdash \ket{t} : \KType(\sigma)}
    \qquad
    \frac{E[\Gamma]\vdash B : \BType(\sigma) \qquad E[\Gamma]\vdash K : \KType(\sigma)}{E[\Gamma] \vdash B \cdot K : \SType}
\end{gather*}

The typing for functions and applications follow the common practice. 
Take the index function $\mu x. t$ as an example: here $x$ is a bound variable typed as $\Index$, and the type $U\{x/u\}$ of application $(t\ u)$ is obtained by replacing $x$ with the index instance $u$.
\begin{gather*}
    \frac{E[\Gamma; x : T] \vdash t : U}{E[\Gamma] \vdash (\lambda x : T . t) : T \to U}
    \qquad
    \frac{E[\Gamma] \vdash t:U \to T \qquad E[\Gamma] \vdash u:U}{E[\Gamma] \vdash (t\ u):T} \\
    \\
    \frac{E[\Gamma; x : \Index] \vdash t : U}{E[\Gamma] \vdash (\mu x.t) : \forall x.U}
    \qquad
    \frac{E[\Gamma] \vdash t:\forall x.U \qquad E[\Gamma] \vdash u : \Index}{E[\Gamma] \vdash (t\ u):U\{x/u\}}
\end{gather*}


Lastly, the big operator sum is modelled by folding a function on a set, therefore the typing rule is as follows:
\[
    \frac{E[\Gamma] \vdash s : \SET(\sigma) \qquad E[\Gamma] \vdash f : \Basis(\sigma) \to \KType(\tau)}{E[\Gamma] \vdash \sum_{s} f : \KType(\tau)}.
\]

% And lastly we have the typing rules for composition $x \circ y$. Similar to casual Dirac notation, the typing of composition depends on the types of operands.
% \begin{gather*}
%     \frac{E[\Gamma] \vdash x : \SType \qquad E[\Gamma] \vdash y : \KType(\sigma)}{E[\Gamma] \vdash x \circ y : \KType(\sigma)}
%     \qquad
%     \frac{E[\Gamma] \vdash x : \OType(\sigma, \tau) \qquad E[\Gamma] \vdash y : \KType(\tau)}{E[\Gamma] \vdash x \circ y : \KType(\sigma)}
% \end{gather*}



\begin{lemma}
    The typing of expressions are decidable and unique.
\end{lemma}
\begin{proof}
    The type can be calculated in the recursive manner. There is at most one typing rule for the same function symbol and argument types, which leads to the uniqueness of typing.
\end{proof}

\subsection{Semantics}


% Semantics define the meanings of expressions, and the goal of the desirable algorithm is to decide whether
% two expressions have the equivalent semantics. We can give the semantics by axiomatic equations and the denotational interpretations.

To give meanings to the syntax, we assign the semantics in the denotational way, which is a mapping from syntax to set-theoretical objects.

\subsubsection{Denotational semantics} 
The denotational semantics interpret every expression as an object in linear algebra, according to a valuation mapping $v$ from variables to their values. 
The semantics of $e$ with valuation $v$ is written as $\sem{e}_v$, and two expressions $e_1$ and $e_2$ are equivalence if they have equal semantics in the mathematical sense for all valuations, written as $\sem{e_1} = \sem{e_2}$.

The complete interpretation is listed in~\Cref{sec: full denotational sem}.
Variables typed with $\Index$ are interpreted as finite sets, and index product $\sem{\sigma_1 \times \sigma_2} = \sem{\sigma_1} \times \sem{\sigma_2}$ are defined as Cartesian product of sets. Following on, every type is interpreted as a set. For example, the scalar type $\sem{\SType} = \mathbb{C}$ is interpreted as complex number set, the the ket and bra type $\sem{\KType(\sigma)} = \mathcal{H}_{\sem{\sigma}}$, $\sem{\KType(\sigma)} = \mathcal{H}_{\sem{\sigma}}^*$ are interpreted as the Hilbert space and dual space depending on $\sigma$. One special case is the delta symbol 
$\sem{\delta_{s, t}} = 
\left \{  
    \begin{array}{ll}
        1, & \text{where } \sem{s} = \sem{t}, \\
        0, & \text{where } \sem{s} \neq \sem{t}.
    \end{array} 
\right .
$.

The idea behind the interpretation of types and terms is to characterize the typing relation with set theory inclusion. Therefore we have the following lemma.
\begin{lemma}
    For all well-formed context $E[\Gamma]$, term $t$ and type $T$, if $E[\Gamma]\vdash t : T$, then for all valuations $v$, $\sem{t}_v \in \sem{T}_v$.
\end{lemma}
\begin{proof}
    Directly check all the cases.
\end{proof}

This explanation formalizes the common explanation of Dirac notation, and best describes the target of the algorithm.
However, computers cannot reason about equivalence through mathematical interpretations. We move on define the proof system as an abstraction.


\subsubsection{Axiomatic semantics} 
The proof system for equivalence consists of equational logic as the framework and axioms describing the properties of Dirac notation.
The full list is in~\Cref{sec: full axioms}.
There are axioms for linear space, and other structures like tensor product and inner product.
% From the operational view, each equation declares a valid rewriting operation, and two expressions are equiavlent if and only if they can be rewritten into the same form using the axioms.
For example, we have the absorption law of zero symbols $X \cdot \mathbf{0} = \mathbf{0}$, and the bilinearity of dot product
\begin{align*}
    (a.X) \cdot Y = a.(X \cdot Y) \qquad X \cdot (Y_1 + Y_2) = X \cdot Y_1 + X \cdot Y_2 \\
    X \cdot (a.Y) = a.(X \cdot Y) \qquad (X_1 + X_2) \cdot Y = X_1 \cdot Y + X_2 \cdot Y
\end{align*}

As is mentioned in the introduction, a subset $E$ of the axioms is not decided by term rewriting. The set consists of:
\begin{align*}
    & \textrm{AC-equivalence} 
    && \textrm{e.g.} \qquad X + Y = Y + X \qquad (X + Y) + Z = X + (Y + Z) \\
    & \textrm{$\alpha$-equivalence}
    && \lambda x . A = \lambda y . A\{x/y\} \\
    & \textrm{SUM-SWAP}
    && \sum_{i \in s_1} \sum_{j \in s_2} A = \sum_{j \in s_2} \sum_{i \in s_1} A \\
    & \textrm{scalar theories} 
    && \textrm{e.g.} \qquad a + 0 = a \qquad a \times (b + c) = a \times b + a \times c
\end{align*}
The equational theories for scalars are treated as a moduloe, and are not considered here. In the implementation, we use the Mathematica kernel to decide scalar equivalences.

The equational axioms provide an operable theory for the proof automation algorithm,
and the denotational semantics can be considered as one model for the theory.
In this sense, the equivalence derived by axioms always imply the equivalence in interpretations.
\begin{lemma}
    For all well-formed context $E[\Gamma]$ and terms $e_1$, $e_2$, if $AX \vdash e_1 = e_2$, then $\sem{e_1} = \sem{e_2}$.
\end{lemma}
\begin{proof}
    Direct check all cases.
\end{proof}

Therefore, the axioms are sound with respect to denotational semantics. 
Unfortunately, the inverse does not hold: there are equivalences in denotational semantics that cannot be captured by these axioms. 
However, our work focuses on solving the practical examples, which are covered by our axioms in the experiments.

To conclude the design introduction, we demonstrate the formalization of symbols used in the motivating example.
\begin{example}[formalizing the motivating example]
    \label{ex: formalizing motivating}
    Definitions and assumptions in the environment $E$:
    \begin{align*}
        & \textrm{TPO} && := \mu T_1. \mu T_2. \lambda O : \OType(T_1, T_2). \sum_{i \in \mathbf{U}(T_1)} \sum_{j \in \mathbf{U}(T_2)} \bra{i} O \ket{j} . \ket{j}\bra{i} \\
        & && : \forall T_1. \forall T_2. \OType(T_1, T_2) \to \OType(T_2, T_1); \\
        & \textrm{phi} && := \mu T. \sum_{i \in \mathbf{U}(T)} \sum_{j \in \mathbf{U}(T)} \ket{(i, j)} : \forall T.\KType(T \times T); \\
        & \textrm{T} && : \Index; \\
        & \textrm{M} && : \OType(T, T).
    \end{align*}
    The symbol TPO is the encoding of operator transpose, which is polymorphic on the Hilbert spaces by $T_1$ and $T_2$.
    phi takes the index $T$ and defines the maximally entangled states. It sums over all basis in $T$, indicated by the universal set $\mathbf{U}(T)$.
    With the assumption of index T and operator M, we can write the equivalence in the non-label version, formally as 
    \[
        (\textrm{M} \otimes \mathbf{1}_\mathcal{O}(\textrm{T})) \cdot (\textrm{phi T}) = (\mathbf{1}_\mathcal{O}(\textrm{T}) \otimes (\textrm{TPO T T M})) \cdot (\textrm{phi T}).
    \]
\end{example}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Algorithm for Deciding Dirac notation equations}
\label{sec: decide}

We use the term rewriting technique to decide the equivalence of Dirac notation implied by its axiomatic semantics.
Term rewriting decides equivalence by normalizing the two terms, and checking whether they have the same syntax.
The normalization is powered by matching and substitution in universal algebra, using a set of rewriting rules.
As is mentioned in the sematnics, the axioms in $E$ cannot be decided by term rewriting.
DiracDec decides $E$ by examining all possible permutations in the rewriting result.
In this work, the general idea is to carry through the normalization procedure using sorting algorithms. 
The procedure of the normalization is displayed below. 
The first three steps use term rewriting to work on the structure of Dirac notation, while the last three steps deals with the equational theory $E$.
\begin{enumerate}
    \item \textbf{first rewritings}: expand definitions and simplify,
    \item \textbf{variable expansion}: consider scalars expressions for completeness,
    \item \textbf{second rewritings}: normalize modulo $E$,
    \item \textbf{sorting without bound variables}: normalize AC-equivalence,
    \item \textbf{swap successive summation}: normalize SUM-SWAP,
    \item \textbf{de Bruijn normalization}: normalize $\alpha$-equivalence.
\end{enumerate}

% \input{flowchart.tex}


\subsection{Normalization modulo $E$ by Term Rewriting}
Term rewriting rules, written as $l \to r$, are used to normalize terms by recursively matching the subterms of the term with the left hand side $l$, and replace them with the corresponding right hand side $r$. The procedure terminates when no more rewritings can be made.
The full list of rewriting rules are in~\Cref{sec: rewriting rules}, and we present some of them to illustrate the design idea.

Firstly, we use the following flattening rule to decide the associative with AC symbols, because we allow functions with indefinite arities.
\[
a_1 + \cdots + (b_1 + \cdots + b_m) + \cdots + a_n
\ \reduce\ a_1 + \cdots + b_1 + \cdots + b_m + \cdots + a_n
\]
Commutativity is left for the sorting algorithm later on. 
Many rewriting rules are obtained by assigning directions to the equational axioms, for example:
\begin{align*}
    &\textrm{(R-DOT6)} && \bra{s} \cdot \ket{t} \ \reduce \delta_{s, t} \\
    &\textrm{(R-DELTA0)} && \delta_{s, s} \ \reduce\ 1 \\
    &\textrm{(R-MULK1)} && O : \OType(\sigma, \tau) \Rightarrow O \cdot \mathbf{0}_{\KType(\tau)} \ \reduce \mathbf{0}_{\KType(\sigma)} \\
    &\textrm{(R-MULK11)} && (O_1 \otimes O_2) \cdot (K_1 \otimes K_2)\ \reduce\ (O_1 \cdot K_1) \otimes (O_2 \cdot K_2)
\end{align*}
Some of them are obvious. The (R-DOT6) says that inner product of two basis will be evaluated to a delta expression,
and (R-DELTA0) further transforms delta on identical basis to scalar $1$.
(R-MULK1) corresponds to the axiom that multiplication on zero vectors results in zero. It has a condition on typing, which is calculated during rewriting.
Some rules require the intuition. For example, (R-MULK11) shows that we prefer tensor product than multiplication.

As a reference, the term rewriting system for DiracDec is proved complete for the axioms, except the sum symbol. The result is obtained by checking confluence and termination of the system. Our rewriting rules are translations from DiracDec into the typed and abstract language, therefore completeness for corresponding symbols is also expected to hold.


%%%%%%%%%%% It's better to avoid mentioning completion rules.
% Other part of rules assign the rewriting diraction to equations according to the property of symbols and intuitive observations of their relations.
% When different rules rewrites the same term to different forms, rules for confluence purpose are added.
% \begin{align*}
%     %
%     & \text{(R-SCR1)} 
%     && a.(b.X) \ \reduce\ (a \times b).X \\
%     %
%     & \text{(R-DOT10)}
%     && (B \cdot O) \cdot K \ \reduce\ B \cdot (O \cdot K), \\
%     %
%     & \text{(R-DOT11)}
%     && \bra{(s, t)} \cdot ((O_1 \otimes O_2) \cdot K) \ \reduce\ ((\bra{s} \cdot O_1) \otimes (\bra{t} \cdot O_2)) \cdot K, \\
%     %
%     & \text{(R-MULB10)}
%     && \bra{(s, t)} \cdot (O_1 \otimes O_2)\ \reduce\ (\bra{s} \cdot O_1) \otimes (\bra{t} \cdot O_2),
% \end{align*}
% The (R-SCR1) rule follows the idea to reduce linear algebra scaling into scalar multiplications,
% and (R-MULB10) transform inner product into tensor product. 
% As an example of the completetion rule, here the normalization of term $(\bra{(s, t)} \cdot (O_1 \otimes O_2)) \cdot K$ have two rewriting paths: (a). apply (R-MULB10) and get $((\bra{s} \cdot O_1) \otimes (\bra{t} \cdot O_2)) \cdot K$, or
% (b). first apply (R-DOT10) and sort the term into $\bra{(s, t)} \cdot ((O_1 \otimes O_2) \cdot K)$, and then apply (R-DOT11) to get the same result. Here (R-DOT11) is for completeness of cases similar to this example.

We have other rules dealing with big operator sum. For example, 
\begin{align*}
    & \textrm{(R-SUM-ELIM2)}
    && i \text{ free in } t \Rightarrow \sum_{i \in \mathbf{U}(\sigma)} \sum_{k_1 \in s_1} \cdots \sum_{k_n \in s_n} (\delta_{i, t}.A) \\
    & && \reduce\ \sum_{k_1 \in s_1} \cdots \sum_{k_n \in s_n} A\{i/t\} \\
    & \textrm{(R-SUM-PUSH5)}
    && (\sum_{i \in M} B)\cdot K \ \reduce\ \sum_{i \in M}(B \cdot K)
\end{align*}
The (R-SUM-ELIM2) rule will try to eliminate the delta expression in summations.
And the (R-SUM-PUSH5) rule will lift sum to the outside of inner product.
There are no completeness guarantee, but the rules work well in practice.



One technique revealed in the DiracDec work is the expansion of variables, critical for proofs with sum:
\begin{gather*}
    \frac{E[\Gamma] \vdash K : \KType(\sigma)}{E[\Gamma] \vdash K \ \reduce\ \sum_{i \in \mathbf{U}(\sigma)}(\bra{i}\cdot K).\ket{i}}
    \qquad \qquad
    \frac{E[\Gamma] \vdash B : \BType(\sigma)}{E[\Gamma] \vdash B \ \reduce\ \sum_{i \in \mathbf{U}(\sigma)}(B \cdot \ket{i}).\bra{i}} \\
    \\
    \frac{E[\Gamma] \vdash O : \OType(\sigma, \tau)}{E[\Gamma] \vdash O \ \reduce\ \sum_{i \in \mathbf{U}(\sigma)} \sum_{j \in \mathbf{U}(\tau)}(\bra{i} \cdot O \cdot \ket{j}).(\ket{i} \cdot \bra{j})}
\end{gather*}
These rules transform variables to the symbolic summation of their decomposition on the basis.
The rules are not terminating, therefore is applied recrusively once in the second step called \textit{variable expansion}. On the other hand, we discovered that doing the expansion on all variables only once is already sufficient.
\begin{lemma}
    Let $\textrm{expand}(e)$ indicate the result of expanding all variables in $e$ once.
    For all well-typed term $e$ in $E[\Gamma]$, $\textrm{expand}(\textrm{expand}(e))$ and $\textrm{expand}(e)$ have the same normal form.
\end{lemma}
\begin{proof}
    If we expand a ket variable twice, the structure will be reduced to
    \[
        \sum_{i \in \mathbf{U}(\sigma)}(\bra{i}\cdot \sum_{j \in \mathbf{U}(\sigma)}(\bra{j}\cdot K).\ket{j}).\ket{i}
        \ \reduce\ 
        \sum_{i \in \mathbf{U}(\sigma)}\sum_{j \in \mathbf{U}(\sigma)}(\bra{j}\cdot K \times \braket{i|j}).\ket{i},
    \]
    the elimination rule of delta symbol returns the term to the one-expansion result. Similar for bra and operator.
\end{proof}



\section{Deciding Equational Theory $E$}

In the Mathematica implementation of DiracDec, the equational theory $E$ is decided by a unification, which tries to find a substitution of summation bound variables that makes the two expressions syntactically equivalent. The unification iterates through all permutations of AC symbol arguments, and the complexity is factorial in the maximum number of AC symbol arguments.

As the first improvement, we check the $\alpha$-equivalence by de Bruijn index~\cite{deBruijn1972lambda}, where references to bound variable names are replaced by the distance of the lambda abstraction to the variable. For example, the nominal lambda abstraction $\lambda x. x$ is transformed into $\lambda . 0$, while $\lambda x. \lambda y. (x\ (y\ x))$ will is transformed into $\lambda.\lambda. (1\ (0\ 1))$. 
Transformation into de Bruijn index is at the last step of the normalization to check the equivalence of terms with different bound variable names.

The remaining axioms of AC-equivalence and SUM-SWAP claims equivalence under permutations.
A standard approach to decide is normalization by sorting in a given order. For example, given the dictionary order $a < b < c$, the term $b + c + a$ (and any other AC equivalent ones) will be normalized into $a + b + c$. For our setting, there are two difficulties intertwined together: how to assign such an order to all terms in our language, and how to sort for the two axioms simultaneously.
As a typical example, the two terms 
\[
    \sum_{i \in s_1} \sum_{j \in s_2} \bra{i}A\ket{j} \times \bra{j}B\ket{i}
    = 
    \sum_{i \in s_2} \sum_{j \in s_1} \bra{i}B\ket{j} \times \bra{j}A\ket{i}
\]
are equivalent. However, directly sorting elemnts of scalar multiplication in the lexical order will not lead to the same form.

We propose an algorithm to solve the problem by sorting without bound variables. The observation is that in a successive sum expression $\sum_{i \in s_1}\cdots\sum_{j \in s_n}A$, the name and order of bound variables $i, \cdots, j$ can be permuted freely. Therefore, all bound variables should be treated uniformly during sorting, and the order of sum can then be decided according to the position of their bound variables.

In the above example, we ignore the bound variables first, and sort the sum body into $\bra{\bullet}A\ket{\bullet} \times \bra{\bullet}B\ket{\bullet}$. Then we swap the sum, so that the bound variable at first $\bullet$ position appears at the outmost position. The results will have the same de Bruijn normal form, namely $\sum_{s_1} \sum_{s_2} \bra{\$1} A \ket{\$0} \times \bra{\$0} B \ket{\$1}$.

To describe the algorithm in the following, we introduce two notations: for a term $e = f(a_1, a_2, \cdots, a_n)$, $\textrm{head}(e)$ indicates the function symbol $f$,
and $\textrm{arg}(e, i)$ indicates the $i$-th argument $a_i$. 
% Variables and constants are considered as functions with zero arguments.
\begin{definition}[order without bound variables]
    Assume we have a total order of all symbols.
    Let $\mathcal{B}$ be the set of bound variables.
    For simplicity, we assume all bound variables are unique.
    The relation $e_1 =_\mathcal{B} e_2$ holds when
    \begin{itemize}
        \item $head(e_1) = head(e_2)$ and $arg(e_1, i) =_\mathcal{B} arg(e_2, i)$ for all $i$, or
        \item $e_1 \in \mathcal{B}$ and $e_2 \in \mathcal{B}$.
    \end{itemize} 

    The relation $e_1 <_\mathcal{B} e_2$ between the two terms holds when:
    \begin{itemize}
        \item $e_1 \notin \mathcal{B}$ and $e_2 \in \mathcal{B}$, or
        \item $head(e_1) < head(e_2)$, or
        \item $head(e_1) = head(e_2)$, and there exists $n$ with $arg(e_1, n) <_\mathcal{B} arg(e_2, n)$, where $arg(e_1, i) =_\mathcal{B} arg(e_2, i)$ for all $i < n$.
    \end{itemize}
\end{definition}
It can be checked that $e_1 =_\mathcal{B} e_2$ if and only if neither $e_1 <_\mathcal{B} e_2$ or $e_2 <_\mathcal{B} e_1$ holds.
The idea is to compare the function symbols in the top down order, and omit bound variable occurance. 
With the order, the sort function normalize the term with respect to AC equivalence.
\begin{definition}[sort transformation]
    For a term $e$ with bound variable set $\mathcal{B}$,
    The sort transformation sort(e) is defined as
    \begin{itemize}
        \item $e$, if $e$ is a variable or constant;
        \item $\lambda x:T. \textrm{sort}(e')$, if $e \equiv \lambda x : T. e'$;
        \item $\mu x. \textrm{sort}(e')$, if $e \equiv \mu x. \textrm{sort}(e')$; or
        \item $f(\textrm{sort}(a_1), \cdots, \textrm{sort}(a_n))$, if $e \equiv f(a_1, \cdots, a_n)$. If $f$ is an AC symbol, then the order of sort($a_i$) is sorted ascendingly according to $<_\mathcal{B}$.
    \end{itemize}
\end{definition}

The order of bound variables can be decided according to the result of the sort transformation, and then successive summations can be normalized using the order.
\begin{definition}[swap transformation]
    For a term $e$ with sorting result sort$(e)$, we can obtain a total order of all bound variables appearing in the term $e$. Specifically, they are ordered by their first appearances, except in function definitions $\lambda x$ and $\mu x$.
    The swap transformation then arrange successive summation according to this order.
\end{definition}

The algorithm succeeds in all equivalences of our benchmark, and we formalize its completeness as a conjecture.
\begin{conjecture}[completeness of transformation]
    For any two terms $e_1$ and $e_2$ that is equivalent under AC equivalence, SUM-SWAP and $\alpha$-equivalence, they will have the same form after sort, swap and de Bruijn transformations.
\end{conjecture}


% The order depends on there occurances in the last sorting result. If no occurance, then the order will depend on the set (for sum) and the type (for lambda abstraction only).

%%%%%%%%%%%%%%%%%%%%%%%


% The idea is to assign an order to terms, which is independent on the bound variables. Because we can have terms with nested AC symbols.

Lastly, we can prove that equivalence by this normalization procedure is sound with respect to the semantics. 
\begin{theorem}[soundness]
    For any well-formed context $E[\Gamma]$ and well-typed expressions $e_1$ and $e_2$, if $e_1\downarrow = e_2\downarrow$, then $\sem{e_1} = \sem{e_2}$.
\end{theorem}
\begin{proof}
    The soundness of term rewriting holds because each rewriting rule preserves the equivalence. The operations in sort and swap transformation follows AC-equivalence and SUM-SWAP axioms. The de Bruijn normal form is sound for $\alpha$-equivalence.
\end{proof}



% Labelled Dirac Notation

\input{labelled}


\section{Implementation and Case Study}

The main purpose of this work is to build a practical tool that works well in checking Dirac notation equations. The refinements and extensions above concludes in our implementation called Dirace, a solver written in \CC. It has a parser built by ANTLR4, and scalar reasonings are powered by a Mathematica kernel. The user can use commands to make definitions and assumptions in the maintained context, conduct the normalization and equivalence checking, and obtain the rewriting trace output. This implementation 
is tested on the benchmark of the DiracDec work, and succeeds in proving most of them efficiently. 
It can be used from the command line interactively, or can be integrated into other \CC\ projects as a library.

\subsubsection{Project Structure}
The project structure is illustrated in~\Cref{fig: dirace structure}.
\texttt{ualg} is the module for universal algebra, defining basic concepts like terms and substitutions. It serves as the library for \texttt{dirace}, which are then utilized in the example benchmarks and the toplevel command line application. The components of \texttt{dirace} are as follows:
\begin{itemize}
    \item \texttt{symbols.cpp}: the reserved symbols and AC symbols;
    \item \texttt{syntax\_theory.cpp}: syntax related algorithms, such as de Bruijn normalization and freeness of variables;
    \item \texttt{calculus.cpp}: type checker and intergration with Mathematica;
    \item \texttt{reduction.cpp}: all the rewriting rules and transformations;
    \item \texttt{dirac\_parser.cpp}: parser for Dirac notation and Dirace commands;
    \item \texttt{prover.cpp}: the prover that maintains the context and process commands like definition or equivalence checking.
\end{itemize}

\input{dirace.tex}

The internal data structure for terms is a pointer-based syntax tree following the function application style:
\[
    \texttt{
        term ::= ID | ID [term (, term)*].
    }
\]
The syntax tree can be an identifier, or an application with an identifier as the function head, and several syntax trees as arguments. There are several Dirac notation terms and their corresponding syntax trees.
\footnotesize{
\begin{align*}
    & X_1 + X_2 + X_3 && \texttt{ADD[X1, X2, X3]} 
    \\
    & \lambda x: \OType(T_1,  T_2). x^\dagger && \texttt{FUN[x, OTYPE[T1, T2], ADJ[x]]}
    \\
    & \sum_{i \in \mathbf{U}(T)} \ket{i} \bra{i} && \texttt{SUM[USET[T], FUN[i, BASIS[T], OUTER[KET[i], BRA[i]]]]}
\end{align*}
}
The syntax tree structure is also compatible with the datatype of Mathematica. This improves the interoperability between Dirace and the Mathematica system, enabling them to work interleavingly.
To improve usability, Dirace also supports many special syntacies for terms,  and most Dirac notation terms will be encoded in the natural way.
Here are some examples for the parsing syntax.

\begin{figure}
    \center
\begin{tabular}{c >{\centering\arraybackslash}p{4cm} l}
    \hline
    syntax & parsing result & explanation \\
    \hline
    \texttt{|e>} & \texttt{KET[e]} & the ket basis\\
    \texttt{e1 + ... + en} & \texttt{ADD[e1, ..., en]} & the addition\\
    \texttt{e1\ e2} & \texttt{COMPO[e1, e2]} & composition in Dirac notation \\
    \texttt{e1\^{}*} & \texttt{CONJ[e1]} & scalar conjugation \\
    \texttt{fun i : T => X} & \texttt{FUN[i, T, X]} & lambda abstraction \\
    \hline
\end{tabular}
\end{figure}

Finally, Dirace uses a prover to host the computation. The prover maintains a well-formed context $E[\Gamma]$, and processes commands to modify the context and conduct calculations. The commands are listed below.
\begin{itemize}
    \item \texttt{\textcolor{NavyBlue}{Def} ID := term.} It defines the \texttt{ID} as the \texttt{term}, using the \textbf{W-Def} typing rule.
    \item \texttt{\textcolor{NavyBlue}{Var} ID := term.} It make an assumption of \texttt{ID} with the \texttt{term} as type, using the \textbf{W-AssumeE} typing rules.
    \item \texttt{\textcolor{NavyBlue}{Check} term.} Type checking the \texttt{term} and output the result.
    \item \texttt{\textcolor{NavyBlue}{Normalize} term.} Normalize the \texttt{term} using the algorithm introduced in~\Cref{sec: decide}.
    \item \texttt{\textcolor{NavyBlue}{CheckEq} term \textcolor{NavyBlue}{with} term.} Check the equivalence of the two terms calculating and comparing their normal forms.
\end{itemize}
The prover will type check the terms for each command. We can also use \texttt{\textcolor{NavyBlue}{Normalize} term \textcolor{NavyBlue}{with trace}.} to output the proof trace during normalization. The proof trace is a sequence of records, including the rule or transformation appied, the position of application, and the pre- and post-transformation terms. The record helps understand the normalization procedure better, and can be turned into verified proofs in theorem provers in the future.

\subsubsection{Use Case}
Here we encode the motivating~\Cref{ex: motivating}, examine and explain how it is checked in Dirace. The encoding is shown below.

    \begin{lstlisting}[style=dirace]
Var T : INDEX. Var M : OTYPE[T, T].
Def phi := idx T => Sum nv in USET[T], |(nv, nv)>.
Var r1 : REG[T]. Var r2 : REG[T].
CheckEq M_r1;r1 (phi T)_(r1, r2) with (TPO T T M)_r2;r2 (phi T)_(r1, r2).
    \end{lstlisting}        

The first three lines use the \texttt{\textcolor{NavyBlue}{Var}} and \texttt{\textcolor{NavyBlue}{Def}} commands to set up the context for the Dirac notation.
\texttt{T} is a type index, representing arbitrary Hilbert space types. \texttt{M} is assume to be an operator in the Hilbert space with type \texttt{T}. \texttt{phi} is defined as the maximally entangled state, depending on the bound variable \texttt{T} as index.
\texttt{r1} and \texttt{r2} are register names for the two subsystems.

In the left hand side of \texttt{\textcolor{NavyBlue}{CheckEq}} command, \texttt{M\_r1;r1} denotes the labelled notation $M_{r_1; r_1}$, and \texttt{(phi T)\_(r1, r2)} denotes the entangled state $\ket{\Phi}_{(r_1, r_2)}$. They are connected by a white space, which is parsed into the composition of Dirac notation, and will be reduced into the operator-ket multiplication after typing. The right hand side is interpreted similarly, except the defined symbol \texttt{TPO} in the environment:

\begin{lstlisting}[style=dirace]
Def TPO := idx sigma => idx tau => fun O : OTYPE[sigma, tau] => Sum i in USET[sigma], Sum j in USET[tau], (<i| O |j>).(|j> <i|).
\end{lstlisting}

The \texttt{TPO} symbol represents the transpose of operators, and encodes the formalization in~\Cref{ex: formalizing motivating}. Thanks to the design of environment and functions, many other commonly used symbols in Dirac notation are encoded and provided as defined symbols in Dirace.

Within one second, the prover reports the result of equivalence with their common normal form:
    \begin{lstlisting}[style=dirace]
The two terms are equal.
[Normalized Term] SUM[USET[T], FUN[BASIS[T], SUM[USET[T], FUN[BASIS[T], SCR[DOT[BRA[$\texttt{\$1}$], MULK[M, KET[$\texttt{\$0}$]]], LTSR[LKET[$\texttt{\$1}$, r1], LKET[$\texttt{\$0}$, r2]]]]]]] : DTYPE[RSET[r1, r2], RSET]
    \end{lstlisting}

The normal form is in the internal syntax tree format mentioned above. A more readable interpretation is:
\[
\sum_{\mathbf{U}(T)} \sum_{\mathbf{U}(T)} \bra{\$1}M\ket{\$ 0} . \ket{\$1}_{r_1} \otimes \ket{\$0}_{r_2} : \DType(\{r_1, r_2\}, \emptyset).
\]
Here $\$0$ and $\$1$ are de Bruijn indices. The result is a ket on the $\{r_1, r_2\}$ system as expected, and follows pattern proposed in~\Cref{sec: labelled}.




\subsubsection{Benchmark performance}

To evaluate Dirace, we first test the examples from DiracDec benchmark and make a comparison.
The experiments are carried out using a MacBook Pro with M3 Max chip.

\begin{figure}
    \center
    \begin{tabular}{c|c c c|c c c}
        \hline
        \multirow{2}{*}{source} & \multicolumn{3}{c|}{DiracDec} & \multicolumn{3}{c}{Dirace} \\
        \cline{2-7}
                                 & expressable & success & time(s)           & expressable & success & time(s)                 \\
        \hline
        textbook(QCQI)          & 18          & 18        &    1.02        &    18      & 18          &   0.82      \\
        CoqQ                    & 162          & 156       &    48.69       &   158     &  158   &     9.74     \\
        circuits                 & 2          & 2       &    17.67       &   3     &  2   &     1.4     \\
        research paper                & 4          & 4         &  59.53       &   4    & 4       &  0.73     \\
        \hline
    \end{tabular}        
    \caption{For DiracDec, examples that cannot be decided within 60 seconds are not included.}
\end{figure}

The timing of Dirace does not include the initialization of Mathematica kernel link, which takes about 3 seconds in the beginning.
As to expressibility, the language for DiracDec has the support for projectors $\texttt{fst}$ and $\texttt{snd}$ on basis pairs, satisfying $\texttt{fst} (s, t) = s$ and $\texttt{snd} (s, t) = t$. We found this feature is almost not used, so we removed the support. As a result, Dirace encodes 158 examples for the CoqQ part, 4 less than DiracDec. For decidability, we improved the rewriting rules about sum for Dirace, and proved several more examples failed by DiracDec. 
The main difference is about their time efficiency. Because of our algorithm to decide AC-equivalence and SUM-SWAP, Dirace has a significant efficiency improvement, especially on those ``computational examples'' mentioned in the DiracDec paper.
One typical example comes from the paper by Jens about the equivalence of operators for qubits. The system has to decompose the term on the concrete $\ket{0}$ and $\ket{1}$ basis, resulting a lot of addition elements. It takes DiracDec about one minute, but Dirace solves it within one second.



We also built an example benchmark for labelled Dirac notation.
\yx{We need examples.}


\section{Related Work}

Automated theorem proving has seen significant advancements in recent years, particularly through the development of satisfiability modulo theories (SMT) solvers,
% SMT solvers extend propositional satisfiability by integrating theories such as arithmetic, arrays, and bit-vectors, making them suitable for solving a wide range of verification problems in both hardware and software domains. 
including prominent tools like Z3. These solvers have become essential in various fields such as formal verification, synthesis, and model checking. 
Equational reasoning is another crucial area of research within automated theorem proving, which focuses on solving problems that involve equations between terms in an algebraic structure. 
Equational provers, such as Vampire and E, have played a pivotal role in addressing the challenge of proving equations in first-order logic, employing sophisticated algorithms like superposition and term rewriting.

Formal verification of quantum computation is receiving increasing attentions during these years. See~\cite{Lewis2023} for a comprehensive review. 
Verification frameworks in Coq include the foundational formalization CoqQ and quantum circuit language QWIRE. 
Verifications of quantum programs are also considered, such as the Hoare logic based methods [] and model checking based methods [].
The equational reasoning of Dirac notation is crucial for establishing property proofs in these works.
Verification theoreis and tools based on other languages are also proposed, such as PyZX for reasoning and simplification of ZX-calculus.




\section{Conclusion and Future Work}
Based on the first equational reasoning tool for Dirac notation called DiracDec, this work improves and extends the theory for practical applications, and provides the solver Dirace. Experiments show that the tool demonstrates advantages in decidability, efficiency and usability. 

We expect Dirace to have applications in areas like quantum program verification or proofs of post-quantum cryptography protocols in the future.
One promising following up is to connect Dirace with theorem provers like Coq. It involves transforming theorem prover expressions into Dirace, and verify the proof trace of Dirace in theorem provers. Besids, most quantum program verifiers nowadays depend on matrix calculations. Dirace can serve as the replacement for matrix methods to enable symbolic deductions.


%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{credits}
%     \subsubsection{\ackname} A bold run-in heading in small font size at the end of the paper is
%     used for general acknowledgments, for example: This study was funded
%     by X (grant number Y).
% \end{credits}
    
    


%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{ref}
%

\appendix
\include{appendix}

\end{document}